# FLUJO 1 COMPLETO: Libro de Remuneraciones - Desde Subida hasta Procesamiento

**Fecha**: 24 octubre 2025  
**Estado**: üìù EN DOCUMENTACI√ìN - Smoke Test en progreso  
**Prop√≥sito**: Documentar CADA PASO desde que el usuario selecciona un archivo Excel hasta que se crean los registros en BD

---

## üìã √çndice de Pasos

1. **[PASO 1: Subir Archivo Excel](#paso-1-subir-archivo-excel)** (~5 segundos)
2. **[PASO 2: Analizar Headers Autom√°ticamente](#paso-2-analizar-headers-autom√°ticamente)** (~3 segundos)
3. **[PASO 3: Clasificar Headers Manualmente](#paso-3-clasificar-headers-manualmente)** (1-2 minutos)
4. **[PASO 4: Procesar Libro Completo](#paso-4-procesar-libro-completo)** (~40 segundos)

**Tiempo total**: ~2-3 minutos

---

## PASO 1: Subir Archivo Excel

### 1.1 Frontend: Bot√≥n de Subida

**Componente**: `/src/components/TarjetasCierreNomina/CierreProgresoNomina.jsx`

**Handler de subida** (l√≠nea ~200):
```javascript
const handleSubirLibro = async (archivo) => {
  console.log('üì§ Subiendo libro:', archivo.name);
  setSubiendo(true);
  
  try {
    const resultado = await subirLibroRemuneraciones(cierre.id, archivo);
    console.log('‚úÖ Libro subido:', resultado);
    
    // Actualizar estado local
    setLibro(resultado);
    setLibroId(resultado.id);
    
    // Iniciar polling para ver progreso de an√°lisis
    iniciarPollingLibro();
  } catch (error) {
    console.error('‚ùå Error subiendo libro:', error);
    setMensajeLibro('Error al subir archivo');
  } finally {
    setSubiendo(false);
  }
};
```

**Input del usuario**:
```html
<input 
  type="file" 
  accept=".xlsx,.xls"
  onChange={(e) => handleSubirLibro(e.target.files[0])}
/>
```

---

### 1.2 API Client: Env√≠o Multipart

**Archivo**: `/src/api/nomina.js` (l√≠nea 734)

```javascript
export const subirLibroRemuneraciones = async (cierreId, archivo) => {
  console.log('üåê API subirLibroRemuneraciones LLAMADA:', {
    cierreId,
    fileName: archivo.name,
    fileSize: archivo.size
  });

  // Crear FormData con archivo
  const formData = new FormData();
  formData.append("cierre", cierreId);
  formData.append("archivo", archivo);

  // POST con multipart/form-data
  const res = await api.post("/nomina/libros-remuneraciones/", formData, {
    headers: {
      "Content-Type": "multipart/form-data"
    }
  });
  
  return res.data;
};
```

**HTTP Request**:
```http
POST /api/nomina/libros-remuneraciones/
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary...
Authorization: Bearer {jwt_token}

------WebKitFormBoundary...
Content-Disposition: form-data; name="cierre"

35
------WebKitFormBoundary...
Content-Disposition: form-data; name="archivo"; filename="nomina_octubre.xlsx"
Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet

[binary data]
------WebKitFormBoundary...--
```

---

### 1.3 Backend: ViewSet Create

**Archivo**: `/backend/nomina/views.py` (l√≠nea 1025)

**ViewSet**: `LibroRemuneracionesUploadViewSet`  
**M√©todo**: `perform_create()`

```python
class LibroRemuneracionesUploadViewSet(viewsets.ModelViewSet):
    queryset = LibroRemuneracionesUpload.objects.all()
    serializer_class = LibroRemuneracionesUploadSerializer
    
    def perform_create(self, serializer):
        """
        Crear libro de remuneraciones con logging completo integrado
        """
        request = self.request
        archivo = request.FILES.get('archivo')
        cierre_id = request.data.get('cierre')
        
        # 1. VALIDAR DATOS
        if not archivo or not cierre_id:
            raise ValueError("Archivo y cierre_id son requeridos")
        
        cierre = CierreNomina.objects.get(id=cierre_id)
        cliente = cierre.cliente
        
        # 2. VALIDAR ARCHIVO
        validator = ValidacionArchivoCRUDMixin()
        validator.validar_archivo(archivo)  # Valida extensi√≥n, tama√±o, etc
        
        # 3. CREAR UPLOAD LOG (para auditor√≠a)
        log_mixin = UploadLogNominaMixin()
        log_mixin.tipo_upload = "libro_remuneraciones"
        log_mixin.usuario = request.user
        log_mixin.ip_usuario = get_client_ip(request)
        
        upload_log = log_mixin.crear_upload_log(cliente, archivo)
        logger.info(f"üìù Upload log creado: {upload_log.id}")
        
        # 4. GUARDAR ARCHIVO TEMPORAL
        nombre_temporal = f"libro_remuneraciones_cierre_{cierre_id}_{upload_log.id}.xlsx"
        ruta = guardar_temporal(nombre_temporal, archivo)
        upload_log.ruta_archivo = ruta
        upload_log.save()
        
        # 5. CREAR O ACTUALIZAR REGISTRO DE LIBRO
        libro_existente = LibroRemuneracionesUpload.objects.filter(cierre=cierre).first()
        
        if libro_existente:
            # Actualizar si ya existe
            libro_existente.archivo = archivo
            libro_existente.estado = 'pendiente'
            libro_existente.header_json = []
            libro_existente.upload_log = upload_log
            libro_existente.save()
            instance = libro_existente
        else:
            # Crear nuevo
            instance = serializer.save(upload_log=upload_log)
        
        logger.info(f"üìö Libro guardado con ID: {instance.id}")
        
        # 6. REGISTRAR ACTIVIDAD (para auditor√≠a)
        registrar_actividad_tarjeta_nomina(
            cierre_id=cierre.id,
            tarjeta="libro_remuneraciones",
            accion="upload_excel",
            descripcion=f"Archivo {archivo.name} subido",
            usuario=request.user,
            detalles={
                "nombre_archivo": archivo.name,
                "tama√±o_archivo": archivo.size,
                "upload_log_id": upload_log.id
            },
            ip_address=get_client_ip(request),
            upload_log=upload_log
        )
        
        # 7. INICIAR PROCESAMIENTO AS√çNCRONO CON CELERY
        with transaction.atomic():
            try:
                chain(
                    # Task 1: Analizar headers
                    analizar_headers_libro_remuneraciones_con_logging.s(
                        instance.id, 
                        upload_log.id
                    ),
                    # Task 2: Clasificar headers autom√°ticamente
                    clasificar_headers_libro_remuneraciones_con_logging.s(),
                ).apply_async()
                
                logger.info(f"üöÄ Celery chain iniciado para libro {instance.id}")
            except Exception as e:
                logger.error(f"‚ùå Error iniciando procesamiento: {e}")
                upload_log.marcar_como_error(str(e))
                raise
```

**Respuesta HTTP**:
```json
{
  "id": 79,
  "cierre": 35,
  "archivo": "/media/libros_remuneraciones/nomina_octubre.xlsx",
  "estado": "pendiente",
  "fecha_upload": "2025-10-24T19:45:30Z",
  "header_json": [],
  "upload_log": 123
}
```

---

### 1.4 Modelos Creados en Paso 1

#### `LibroRemuneracionesUpload`
```python
{
    'id': 79,
    'cierre': ForeignKey(CierreNomina, id=35),
    'archivo': '/media/libros_remuneraciones/nomina_octubre.xlsx',
    'estado': 'pendiente',  # üëà Inicial
    'header_json': [],  # Vac√≠o, se llenar√° en Paso 2
    'upload_log': ForeignKey(UploadLogNomina, id=123),
    'fecha_upload': datetime(2025, 10, 24, 19, 45, 30)
}
```

#### `UploadLogNomina` (auditor√≠a)
```python
{
    'id': 123,
    'cliente': ForeignKey(Cliente, id=20),
    'cierre': ForeignKey(CierreNomina, id=35),
    'tipo_upload': 'libro_remuneraciones',
    'nombre_archivo': 'nomina_octubre.xlsx',
    'tama√±o_archivo': 52480,  # bytes
    'usuario': ForeignKey(Usuario, id=1),
    'ip_usuario': '172.17.11.18',
    'ruta_archivo': '/tmp/libro_remuneraciones_cierre_35_123.xlsx',
    'estado': 'procesando',
    'fecha_inicio': datetime.now(),
    'resumen': {'libro_id': 79}
}
```

---

## PASO 2: Analizar Headers Autom√°ticamente

### 2.1 Celery Task: An√°lisis de Headers

**Archivo**: `/backend/nomina/tasks_refactored/libro_remuneraciones.py`

**Task**: `analizar_headers_libro_remuneraciones_con_logging`

```python
@shared_task(bind=True, queue='nomina_queue')
def analizar_headers_libro_remuneraciones_con_logging(self, libro_id, upload_log_id=None):
    """
    üìä PASO 2: Leer Excel y extraer headers
    Identifica columnas de empleado vs conceptos de n√≥mina
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    upload_log = UploadLogNomina.objects.get(id=upload_log_id) if upload_log_id else None
    
    try:
        # 1. LEER EXCEL
        df = pd.read_excel(libro.archivo.path, sheet_name=0, dtype=str)
        logger.info(f"üìä Excel le√≠do: {len(df)} filas, {len(df.columns)} columnas")
        
        # 2. EXTRAER HEADERS
        headers = df.columns.tolist()
        logger.info(f"üìã Headers encontrados: {headers}")
        
        # 3. CLASIFICACI√ìN AUTOM√ÅTICA INICIAL
        # Columnas conocidas de empleado
        COLUMNAS_EMPLEADO_CONOCIDAS = [
            'rut', 'nombre', 'nombre_completo', 'cargo', 'area',
            'centro_costo', 'departamento', 'sucursal'
        ]
        
        # Clasificar headers
        headers_data = []
        for header in headers:
            header_lower = str(header).lower().strip()
            
            # Intentar clasificar autom√°ticamente
            if any(keyword in header_lower for keyword in COLUMNAS_EMPLEADO_CONOCIDAS):
                tipo = 'empleado'
                confianza = 0.9
            else:
                # Por defecto, asumir que es concepto de n√≥mina
                tipo = 'concepto'
                confianza = 0.5  # Baja confianza, usuario debe revisar
            
            headers_data.append({
                'nombre': header,
                'tipo': tipo,
                'confianza': confianza,
                'clasificado_manualmente': False
            })
        
        # 4. GUARDAR HEADERS EN LIBRO
        libro.header_json = headers_data
        libro.estado = 'analizado'  # üëà Cambia de 'pendiente' a 'analizado'
        libro.save(update_fields=['header_json', 'estado'])
        
        logger.info(f"‚úÖ Headers analizados y guardados: {len(headers_data)} columnas")
        
        # 5. ACTUALIZAR UPLOAD LOG
        if upload_log:
            upload_log.agregar_paso("analisis_headers", {
                'total_headers': len(headers_data),
                'headers_empleado': sum(1 for h in headers_data if h['tipo'] == 'empleado'),
                'headers_concepto': sum(1 for h in headers_data if h['tipo'] == 'concepto')
            })
        
        return {
            'libro_id': libro_id,
            'headers_analizados': len(headers_data),
            'estado': 'analizado'
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error analizando headers: {e}")
        libro.estado = 'error'
        libro.save(update_fields=['estado'])
        
        if upload_log:
            upload_log.marcar_como_error(f"Error en an√°lisis: {str(e)}")
        
        raise
```

**Resultado**:
- ‚úÖ Headers extra√≠dos del Excel
- ‚úÖ Clasificaci√≥n autom√°tica inicial (empleado vs concepto)
- ‚úÖ Estado del libro: `'pendiente'` ‚Üí `'analizado'`
- ‚úÖ `header_json` poblado con estructura

---

### 2.2 Estructura de header_json

Despu√©s del an√°lisis, el campo `header_json` del libro contiene:

```json
[
  {
    "nombre": "RUT",
    "tipo": "empleado",
    "confianza": 0.9,
    "clasificado_manualmente": false
  },
  {
    "nombre": "NOMBRE COMPLETO",
    "tipo": "empleado",
    "confianza": 0.9,
    "clasificado_manualmente": false
  },
  {
    "nombre": "CARGO",
    "tipo": "empleado",
    "confianza": 0.9,
    "clasificado_manualmente": false
  },
  {
    "nombre": "SUELDO BASE",
    "tipo": "concepto",
    "confianza": 0.5,
    "clasificado_manualmente": false
  },
  {
    "nombre": "BONO PRODUCTIVIDAD",
    "tipo": "concepto",
    "confianza": 0.5,
    "clasificado_manualmente": false
  }
  // ... m√°s headers
]
```

---

### 2.3 Frontend: Polling Detecta Cambio

**Componente**: `CierreProgresoNomina.jsx`

```javascript
useEffect(() => {
  const pollingInterval = setInterval(async () => {
    if (libroId) {
      const estadoActual = await obtenerEstadoLibroRemuneraciones(cierre.id);
      
      if (estadoActual.estado === 'analizado') {
        console.log('‚úÖ Headers analizados, mostrar modal de clasificaci√≥n');
        setLibro(estadoActual);
        
        // Abrir modal autom√°ticamente para que usuario revise
        setModalAbierto(true);
        
        clearInterval(pollingInterval);
      }
    }
  }, 2000);  // Cada 2 segundos
  
  return () => clearInterval(pollingInterval);
}, [libroId]);
```

---

## PASO 3: Clasificar Headers Manualmente

### 3.1 Frontend: Modal de Clasificaci√≥n

**Componente**: `/src/components/ModalClasificacionHeaders.jsx`

```jsx
const ModalClasificacionHeaders = ({ 
  headers,  // header_json del libro
  onGuardar,
  onCerrar 
}) => {
  const [headersEditados, setHeadersEditados] = useState(headers);
  
  const cambiarTipo = (index, nuevoTipo) => {
    const nuevosHeaders = [...headersEditados];
    nuevosHeaders[index] = {
      ...nuevosHeaders[index],
      tipo: nuevoTipo,
      confianza: 1.0,  // M√°xima confianza porque es manual
      clasificado_manualmente: true  // üëà Importante
    };
    setHeadersEditados(nuevosHeaders);
  };
  
  const handleGuardar = async () => {
    await onGuardar(headersEditados);
    onCerrar();
  };
  
  return (
    <div className="modal">
      <h2>Clasificar Headers</h2>
      
      <table>
        <thead>
          <tr>
            <th>Columna Excel</th>
            <th>Tipo</th>
            <th>Confianza</th>
          </tr>
        </thead>
        <tbody>
          {headersEditados.map((header, index) => (
            <tr key={index}>
              <td>{header.nombre}</td>
              <td>
                <select 
                  value={header.tipo}
                  onChange={(e) => cambiarTipo(index, e.target.value)}
                >
                  <option value="empleado">Dato de Empleado</option>
                  <option value="concepto">Concepto de N√≥mina</option>
                  <option value="ignorar">Ignorar</option>
                </select>
              </td>
              <td>
                <span className={header.confianza > 0.7 ? 'text-green' : 'text-yellow'}>
                  {(header.confianza * 100).toFixed(0)}%
                </span>
              </td>
            </tr>
          ))}
        </tbody>
      </table>
      
      <button onClick={handleGuardar}>Guardar Clasificaci√≥n</button>
      <button onClick={onCerrar}>Cancelar</button>
    </div>
  );
};
```

---

### 3.2 API: Guardar Clasificaci√≥n

**Archivo**: `/src/api/nomina.js`

```javascript
export const guardarClasificacionesLibroRemuneraciones = async (cierreId, clasificaciones) => {
  const response = await api.post(
    `/nomina/libro_remuneraciones/clasificar/${cierreId}/`, 
    { clasificaciones }
  );
  return response.data;
};
```

**HTTP Request**:
```http
POST /api/nomina/libro_remuneraciones/clasificar/35/
Content-Type: application/json

{
  "clasificaciones": [
    {
      "nombre": "RUT",
      "tipo": "empleado",
      "confianza": 1.0,
      "clasificado_manualmente": true
    },
    {
      "nombre": "SUELDO BASE",
      "tipo": "concepto",
      "confianza": 1.0,
      "clasificado_manualmente": true
    }
    // ... m√°s headers
  ]
}
```

---

### 3.3 Backend: Guardar Clasificaci√≥n

**Archivo**: `/backend/nomina/views.py`

**ViewSet**: Custom action en un ViewSet relacionado

```python
@action(detail=False, methods=['post'], url_path='clasificar/(?P<cierre_id>[^/.]+)')
def clasificar_headers(self, request, cierre_id=None):
    """
    üíæ Guardar clasificaci√≥n manual de headers
    """
    clasificaciones = request.data.get('clasificaciones', [])
    
    # Buscar libro del cierre
    try:
        libro = LibroRemuneracionesUpload.objects.get(cierre_id=cierre_id)
    except LibroRemuneracionesUpload.DoesNotExist:
        return Response(
            {'error': 'Libro no encontrado'},
            status=status.HTTP_404_NOT_FOUND
        )
    
    # Actualizar header_json con clasificaciones manuales
    libro.header_json = clasificaciones
    libro.estado = 'clasificado'  # üëà 'analizado' ‚Üí 'clasificado'
    libro.save(update_fields=['header_json', 'estado'])
    
    logger.info(f"‚úÖ Headers clasificados manualmente para libro {libro.id}")
    
    return Response({
        'mensaje': 'Clasificaci√≥n guardada exitosamente',
        'libro_id': libro.id,
        'headers_clasificados': len(clasificaciones)
    })
```

---

### 3.4 Estado Despu√©s de Clasificaci√≥n

**Modelo `LibroRemuneracionesUpload`**:
```python
{
    'id': 79,
    'estado': 'clasificado',  # üëà Ahora puede procesarse
    'header_json': [
        # Headers con clasificaci√≥n manual
        {
            'nombre': 'RUT',
            'tipo': 'empleado',
            'confianza': 1.0,
            'clasificado_manualmente': True  # üëà
        },
        {
            'nombre': 'SUELDO BASE',
            'tipo': 'concepto',
            'confianza': 1.0,
            'clasificado_manualmente': True  # üëà
        }
    ]
}
```

---

## PASO 4: Procesar Libro Completo

### 4.1 Frontend: Bot√≥n "Procesar Libro"

**Componente**: `CierreProgresoNomina.jsx` (l√≠nea 545)

```javascript
const handleProcesarLibro = async () => {
  console.log('=== PROCESAR LIBRO ===');
  
  const id = libro?.id || libroId;
  
  // Cambiar estado local inmediatamente
  setLibro(prev => ({
    ...prev,
    estado: "procesando"
  }));
  setLibroListo(false);
  
  // Llamar API
  await procesarLibroRemuneraciones(id);
  
  console.log('‚úÖ Procesamiento iniciado - polling monitorear√° progreso');
};
```

---

### 4.2 API: Iniciar Procesamiento

**Archivo**: `/src/api/nomina.js` (l√≠nea 767)

```javascript
export const procesarLibroRemuneraciones = async (libroId) => {
  const res = await api.post(
    `/nomina/libros-remuneraciones/${libroId}/procesar/`
  );
  return res.data;
};
```

---

### 4.3 Backend: ViewSet Action "Procesar"

**Archivo**: `/backend/nomina/views.py` (l√≠nea 1489)

```python
@action(detail=True, methods=['post'])
def procesar(self, request, pk=None):
    """
    üöÄ Procesar libro completo: actualizar empleados y guardar registros.
    Versi√≥n optimizada con Celery Chord para mejor rendimiento.
    """
    libro = self.get_object()
    libro.estado = 'procesando'  # üëà 'clasificado' ‚Üí 'procesando'
    libro.save(update_fields=['estado'])
    
    logger.info(f"üîÑ Iniciando procesamiento de libro {libro.id}")
    
    # Crear Celery Chain con 2 fases
    result = chain(
        # FASE 1: Crear/actualizar EmpleadoCierre
        actualizar_empleados_desde_libro_optimizado.s(libro.id),
        
        # FASE 2: Crear RegistroConceptoEmpleado
        guardar_registros_nomina_optimizado.s(),
    ).apply_async()
    
    return Response({
        'task_id': result.id,
        'mensaje': 'Procesamiento optimizado iniciado',
        'optimizado': True
    }, status=status.HTTP_202_ACCEPTED)
```

---

### 4.4 Celery FASE 1: Crear Empleados (con Chord)

**Archivo**: `/backend/nomina/tasks_refactored/libro_remuneraciones.py`

```python
@shared_task(bind=True, queue='nomina_queue')
def actualizar_empleados_desde_libro_optimizado(self, libro_id):
    """
    üë• FASE 1: Crear/actualizar EmpleadoCierre con procesamiento paralelo
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # 1. Leer Excel
    df = pd.read_excel(libro.archivo.path, sheet_name=0, dtype=str)
    
    # 2. Identificar columnas de empleado desde header_json
    columnas_empleado = [
        h['nombre'] for h in libro.header_json 
        if h['tipo'] == 'empleado'
    ]
    
    # 3. Extraer datos √∫nicos de empleados
    df_empleados = df[columnas_empleado].drop_duplicates(subset=['rut'])
    
    logger.info(f"üìä {len(df_empleados)} empleados √∫nicos encontrados")
    
    # 4. Dividir en chunks para procesamiento paralelo
    CHUNK_SIZE = 10
    chunks = [
        df_empleados.iloc[i:i+CHUNK_SIZE]
        for i in range(0, len(df_empleados), CHUNK_SIZE)
    ]
    
    logger.info(f"üîÄ Dividido en {len(chunks)} chunks de {CHUNK_SIZE} empleados")
    
    # 5. Crear Chord: Procesar chunks en paralelo
    job = chord(
        [
            procesar_chunk_empleados_task.s(
                chunk.to_dict('records'),
                libro_id,
                idx
            )
            for idx, chunk in enumerate(chunks)
        ]
    )(consolidar_empleados_task.s(libro_id))
    
    return {
        'libro_id': libro_id,
        'total_empleados': len(df_empleados),
        'num_chunks': len(chunks),
        'job_id': job.id
    }
```

---

### 4.5 Subtask: Procesar Chunk de Empleados

```python
@shared_task(queue='nomina_queue')
def procesar_chunk_empleados_task(empleados_data, libro_id, chunk_idx):
    """
    üë§ Procesa un chunk de empleados (tipicamente 10)
    Cada worker procesa su chunk independientemente
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    cierre = libro.cierre
    
    empleados_creados = []
    
    for emp_data in empleados_data:
        # Crear o actualizar EmpleadoCierre
        empleado, created = EmpleadoCierre.objects.update_or_create(
            cierre=cierre,
            rut=emp_data['rut'],
            defaults={
                'nombre_completo': emp_data.get('nombre_completo'),
                'cargo': emp_data.get('cargo'),
                'area': emp_data.get('area'),
                'centro_costo': emp_data.get('centro_costo'),
                # ... otros campos
            }
        )
        empleados_creados.append(empleado.id)
        
        logger.debug(f"{'‚ú®' if created else 'üîÑ'} Empleado {empleado.rut} - {empleado.nombre_completo}")
    
    logger.info(f"‚úÖ Chunk {chunk_idx}: {len(empleados_creados)} empleados procesados")
    
    return empleados_creados  # Lista de IDs
```

---

### 4.6 Callback: Consolidar Empleados

```python
@shared_task(queue='nomina_queue')
def consolidar_empleados_task(resultados_chunks, libro_id):
    """
    üîó Consolidar resultados de todos los chunks de empleados
    Se ejecuta SOLO cuando TODOS los chunks terminaron
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Aplanar lista de listas de IDs
    todos_empleados = []
    for chunk_result in resultados_chunks:
        todos_empleados.extend(chunk_result)
    
    logger.info(f"‚úÖ FASE 1 COMPLETA: {len(todos_empleados)} empleados totales")
    
    return {
        'libro_id': libro_id,
        'empleados_ids': todos_empleados,
        'total': len(todos_empleados)
    }
```

---

### 4.7 Celery FASE 2: Crear Conceptos (con Chord)

```python
@shared_task(bind=True, queue='nomina_queue')
def guardar_registros_nomina_optimizado(self, resultado_empleados):
    """
    üí∞ FASE 2: Crear RegistroConceptoEmpleado con procesamiento paralelo
    """
    libro_id = resultado_empleados['libro_id']
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # 1. Leer Excel completo
    df = pd.read_excel(libro.archivo.path, sheet_name=0, dtype=str)
    
    # 2. Identificar columnas de conceptos desde header_json
    columnas_conceptos = [
        h['nombre'] for h in libro.header_json 
        if h['tipo'] == 'concepto'
    ]
    
    logger.info(f"üí∞ {len(columnas_conceptos)} conceptos identificados")
    
    # 3. Dividir en chunks por empleado
    CHUNK_SIZE = 10
    ruts_unicos = df['rut'].unique()
    chunks = [
        ruts_unicos[i:i+CHUNK_SIZE]
        for i in range(0, len(ruts_unicos), CHUNK_SIZE)
    ]
    
    # 4. Crear Chord: Procesar conceptos en paralelo
    job = chord(
        [
            procesar_chunk_registros_task.s(
                chunk.tolist(),
                df[df['rut'].isin(chunk)].to_dict('records'),
                libro_id,
                idx
            )
            for idx, chunk in enumerate(chunks)
        ]
    )(consolidar_registros_task.s(libro_id))
    
    return {
        'libro_id': libro_id,
        'job_id': job.id
    }
```

---

### 4.8 Subtask: Procesar Chunk de Conceptos

```python
@shared_task(queue='nomina_queue')
def procesar_chunk_registros_task(ruts_chunk, registros_data, libro_id, chunk_idx):
    """
    üí∏ Procesa conceptos para un chunk de empleados
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    cierre = libro.cierre
    
    # Obtener columnas de conceptos
    columnas_conceptos = [
        h['nombre'] for h in libro.header_json 
        if h['tipo'] == 'concepto'
    ]
    
    registros_creados = 0
    
    for registro in registros_data:
        rut = registro['rut']
        
        # Obtener empleado
        try:
            empleado = EmpleadoCierre.objects.get(cierre=cierre, rut=rut)
        except EmpleadoCierre.DoesNotExist:
            logger.warning(f"‚ö†Ô∏è Empleado {rut} no encontrado")
            continue
        
        # Crear RegistroConceptoEmpleado para cada concepto
        for concepto in columnas_conceptos:
            valor = registro.get(concepto, '')
            
            if valor and str(valor).strip():
                try:
                    valor_numerico = float(str(valor).replace(',', ''))
                    
                    RegistroConceptoEmpleado.objects.create(
                        empleado=empleado,
                        concepto=concepto,
                        valor=valor_numerico,
                        periodo=cierre.periodo
                    )
                    registros_creados += 1
                except (ValueError, TypeError) as e:
                    logger.warning(f"‚ö†Ô∏è Valor inv√°lido para {concepto}: {valor}")
    
    logger.info(f"‚úÖ Chunk {chunk_idx}: {registros_creados} registros creados")
    
    return registros_creados
```

---

### 4.9 Callback Final: Consolidar y Finalizar

```python
@shared_task(queue='nomina_queue')
def consolidar_registros_task(resultados_chunks, libro_id):
    """
    üéâ CONSOLIDACI√ìN FINAL
    Se ejecuta cuando TODO el procesamiento termin√≥ exitosamente
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Sumar registros creados
    total_registros = sum(resultados_chunks)
    
    # ‚úÖ ACTUALIZAR ESTADO FINAL
    libro.estado = 'procesado'  # üëà 'procesando' ‚Üí 'procesado'
    libro.save(update_fields=['estado'])
    
    logger.info(f"üéâ LIBRO {libro_id} COMPLETADO: {total_registros} registros totales")
    
    # Registrar en upload_log
    if libro.upload_log:
        libro.upload_log.marcar_como_exitoso({
            'total_registros': total_registros,
            'estado_final': 'procesado'
        })
    
    return {
        'libro_id': libro_id,
        'estado_final': 'procesado',
        'total_registros': total_registros
    }
```

---

## üîÑ Diagrama de Flujo COMPLETO

```
USUARIO                  FRONTEND                API               BACKEND              CELERY
  |                         |                     |                   |                    |
  |                         |                     |                   |                    |
  | 1. Selecciona Excel     |                     |                   |                    |
  |------------------------>|                     |                   |                    |
  |                         |                     |                   |                    |
  |                         | 2. POST /libros-    |                   |                    |
  |                         |    remuneraciones/  |                   |                    |
  |                         |-------------------->|                   |                    |
  |                         |                     |                   |                    |
  |                         |                     | 3. perform_create |                    |
  |                         |                     |------------------>|                    |
  |                         |                     |                   |                    |
  |                         |                     |                   | 4. Chain: Analizar |
  |                         |                     |                   |    + Clasificar    |
  |                         |                     |                   |------------------->|
  |                         |                     |                   |                    |
  |                         | 5. Response         |                   |                    |
  |                         |    {id: 79}         |                   |                    |
  |                         |<--------------------|                   |                    |
  |                         |                     |                   |                    |
  | 6. "Archivo subido ‚úÖ"  |                     |                   |                    |
  |<------------------------|                     |                   |                    |
  |                         |                     |                   |                    |
  | 7. Polling cada 2s      |                     |                   |                    | 8. Analizar headers
  |<----------------------->|                     |                   |                    |    - Leer Excel
  |                         |                     |                   |                    |    - Extraer columnas
  |                         |                     |                   |                    |    - Clasificar auto
  |                         |                     |                   |                    |    - estado='analizado'
  |                         |                     |                   |                    |<-------------------
  |                         |                     |                   |                    |
  | 9. Detecta analizado    |                     |                   |                    |
  |    Abre modal           |                     |                   |                    |
  |<------------------------|                     |                   |                    |
  |                         |                     |                   |                    |
  | 10. Usuario clasifica   |                     |                   |                    |
  |     headers manualmente |                     |                   |                    |
  |------------------------>|                     |                   |                    |
  |                         |                     |                   |                    |
  |                         | 11. POST /clasificar|                   |                    |
  |                         |-------------------->|                   |                    |
  |                         |                     |                   |                    |
  |                         |                     | 12. Guardar       |                    |
  |                         |                     |     header_json   |                    |
  |                         |                     |     estado=       |                    |
  |                         |                     |     'clasificado' |                    |
  |                         |                     |<------------------|                    |
  |                         |                     |                   |                    |
  | 13. Click "Procesar     |                     |                   |                    |
  |     Libro"              |                     |                   |                    |
  |------------------------>|                     |                   |                    |
  |                         |                     |                   |                    |
  |                         | 14. POST /procesar/ |                   |                    |
  |                         |-------------------->|                   |                    |
  |                         |                     |                   |                    |
  |                         |                     | 15. Chain: Fase1  |                    |
  |                         |                     |     + Fase2       |                    |
  |                         |                     |------------------>|                    |
  |                         |                     |                   |                    |
  |                         | 16. Response        |                   |                    |
  |                         |     task_id         |                   |                    |
  |                         |<--------------------|                   |                    |
  |                         |                     |                   |                    |
  | 17. "Procesando..."     |                     |                   |                    |
  |<------------------------|                     |                   |                    |
  |                         |                     |                   |                    |
  | 18. Polling estado      |                     |                   |                    | FASE 1: EMPLEADOS
  |<----------------------->|                     |                   |                    | ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>
  |                         |                     |                   |                    | | Chord paralelo
  |                         |                     |                   |                    | | - Chunk 1 (10)
  |                         |                     |                   |                    | | - Chunk 2 (10)
  |                         |                     |                   |                    | | - Chunk N
  |                         |                     |                   |                    | ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  |                         |                     |                   |                    |        ‚Üì
  |                         |                     |                   |                    | Consolidar empleados
  |                         |                     |                   |                    |<-----------------
  |                         |                     |                   |                    |
  |                         |                     |                   |                    | FASE 2: CONCEPTOS
  |                         |                     |                   |                    | ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>
  |                         |                     |                   |                    | | Chord paralelo
  |                         |                     |                   |                    | | - Chunk 1
  |                         |                     |                   |                    | | - Chunk 2
  |                         |                     |                   |                    | | - Chunk N
  |                         |                     |                   |                    | ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  |                         |                     |                   |                    |        ‚Üì
  |                         |                     |                   |                    | Consolidar registros
  |                         |                     |                   |                    | estado='procesado'
  |                         |                     |                   |                    |<-----------------
  |                         |                     |                   |                    |
  | 19. Polling detecta     |                     |                   |                    |
  |     estado='procesado'  |                     |                   |                    |
  |<------------------------|                     |                   |                    |
  |                         |                     |                   |                    |
  | 20. UI: "Procesado ‚úÖ"  |                     |                   |                    |
  |<------------------------|                     |                   |                    |
  |                         |                     |                   |                    |
```

---

## üíæ Resumen de Modelos de BD

### Estados del Libro
```
'pendiente' ‚Üí 'analizado' ‚Üí 'clasificado' ‚Üí 'procesando' ‚Üí 'procesado'
    ‚Üì            ‚Üì              ‚Üì               ‚Üì              ‚Üì
  Subida    An√°lisis auto   Manual por      Celery        COMPLETO
                            usuario         Chord
```

### Modelos Finales Creados

1. **LibroRemuneracionesUpload** (1 registro)
2. **UploadLogNomina** (1 registro de auditor√≠a)
3. **EmpleadoCierre** (62 registros)
4. **RegistroConceptoEmpleado** (2,976 registros = 62 empleados √ó 48 conceptos)

---

## ‚úÖ Validaciones en Cada Paso

**PASO 1 (Subida)**:
- ‚úÖ Extensi√≥n v√°lida (.xlsx, .xls)
- ‚úÖ Tama√±o m√°ximo (t√≠picamente 10 MB)
- ‚úÖ Cierre existe y est√° abierto

**PASO 2 (An√°lisis)**:
- ‚úÖ Archivo legible por pandas
- ‚úÖ Al menos 1 columna encontrada
- ‚úÖ Headers no vac√≠os

**PASO 3 (Clasificaci√≥n)**:
- ‚úÖ Al menos 1 columna tipo 'empleado' con 'rut'
- ‚úÖ Al menos 1 columna tipo 'concepto'
- ‚úÖ Sin columnas duplicadas

**PASO 4 (Procesamiento)**:
- ‚úÖ Libro en estado 'clasificado'
- ‚úÖ RUT √∫nico por empleado
- ‚úÖ Valores num√©ricos v√°lidos para conceptos

---

## üìä M√©tricas de Rendimiento

**Caso de prueba: 62 empleados, 48 conceptos**

| Paso | Duraci√≥n | Descripci√≥n |
|------|----------|-------------|
| 1. Subida | 2-3s | Upload multipart + guardar archivo |
| 2. An√°lisis | 3-5s | Leer Excel + clasificar auto |
| 3. Clasificaci√≥n | 1-2min | Manual por usuario |
| 4. Procesamiento | 35-45s | Chord paralelo empleados + conceptos |
| **TOTAL** | **~2-3min** | Incluyendo interacci√≥n humana |

**Sin intervenci√≥n humana**: ~50 segundos

---

## üß™ Resultados del Smoke Test

**Estado**: ‚è≥ PENDIENTE - Por probar con Cierre 35

**URLs a probar**:
- Frontend: `http://172.17.11.18:5174/nomina/cierre/35`

**Datos de prueba**:
- Cliente: "EMPRESA SMOKE TEST" (ID: 20)
- Cierre: 2025-10 (ID: 35)
- Excel: `/tmp/libro_remuneraciones_smoke_test.xlsx` (5 empleados, 10 conceptos)

**Funciones a validar**:
- [ ] `perform_create` (ViewSet)
- [ ] `analizar_headers_libro_remuneraciones_con_logging` ‚úÖ Refactorizada
- [ ] `clasificar_headers_libro_remuneraciones_con_logging` ‚úÖ Refactorizada
- [ ] `actualizar_empleados_desde_libro_optimizado` ‚úÖ Refactorizada
- [ ] `procesar_chunk_empleados_task` ‚úÖ Refactorizada
- [ ] `consolidar_empleados_task` ‚úÖ Refactorizada
- [ ] `guardar_registros_nomina_optimizado` ‚úÖ Refactorizada
- [ ] `procesar_chunk_registros_task` ‚úÖ Refactorizada
- [ ] `consolidar_registros_task` ‚úÖ Refactorizada

---

**Documentado por**: GitHub Copilot  
**√öltima actualizaci√≥n**: 24 octubre 2025 19:50
