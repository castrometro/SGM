# üîÑ Flujo REAL de Correcci√≥n de Libro para Incidencias

## üìã Estado Actual del Sistema (Actualizado)

### ‚ö†Ô∏è IMPORTANTE: Sistema Legacy vs Sistema Actual

**‚ùå Sistema Legacy (NO SE USA)**:
- `solicitar_recarga_archivos()` en m√∫ltiples ubicaciones ‚Üí **OBSOLETO**
- `aprobar_recarga_archivos()` ‚Üí **NO USADO EN PRODUCCI√ìN**
- Estados `recarga_solicitud_pendiente`, `requiere_recarga_archivos` ‚Üí **LEGACY**

**‚úÖ Sistema Actual en Producci√≥n**:
- Bot√≥n "Corregir Libro" en tarjeta de Incidencias
- Endpoint `/nomina/cierres/{cierre_id}/corregir-libro/`
- Flujo directo: Validar ‚Üí Eliminar previos ‚Üí Subir nuevo ‚Üí Procesar

### Ubicaciones de C√≥digo (Sistema Actual)

#### 1. **Frontend - Bot√≥n "Corregir Libro"**:
- `src/components/TarjetasCierreNomina/IncidenciasEncontradasSection.jsx` l√≠nea 596
- `src/components/TarjetasCierreNomina/CorreccionLibro/LibroRemuneracionesCardCorreccion.jsx`

#### 2. **API Call**:
- `src/api/nomina.js` l√≠nea 1230: `corregirLibroRemuneraciones(cierreId, archivo)`

#### 3. **Backend - Validaci√≥n y Eliminaci√≥n**:
- `backend/nomina/views_correcciones.py` l√≠nea 21: `corregir_libro_view()`
  - Valida archivo (extensi√≥n, tama√±o, patr√≥n de nombre)
  - Elimina uploads anteriores de libro
  - Crea UploadLog con acci√≥n "correccion_eliminacion_previos"
  - NO modifica datos consolidados (solo metadatos de uploads)

#### 4. **Reconciliaci√≥n de Incidencias** (Sistema de Hash):
- `backend/nomina/utils/reconciliacion.py` l√≠nea 50: `reconciliar_cierre_suma_total()`
  - Hash estable por concepto/tipo (no incluye montos)
  - Upsert: actualiza existente o crea nueva
  - Marca como resueltas las que ya no superan umbral

#### 5. **Generaci√≥n Simplificada** (Implementaci√≥n Actual):
- `backend/nomina/utils/DetectarIncidenciasConsolidadas.py` l√≠nea 228: `procesar_incidencias_suma_total_simple()`
  - ‚úÖ Genera hash antes de bulk_create (FIXED)
  - ‚ùå NO hace reconciliaci√≥n (crea siempre nuevas)

---

## üéØ Flujo Completo (Sistema Actual en Producci√≥n)

```mermaid
graph TD
    A[Incidencias Detectadas] --> B{Analista Revisa}
    B -->|Necesita Correcci√≥n| C[Click: Corregir Libro]
    
    C --> D[Modal: LibroRemuneracionesCardCorreccion]
    D --> E[Selecciona Archivo Excel]
    E --> F[Advertencia: Eliminar registros previos]
    
    F --> G{Usuario Confirma}
    G -->|Cancela| D
    G -->|Confirma| H[POST /corregir-libro/]
    
    H --> I[Backend: Validaci√≥n]
    I --> J{Archivo V√°lido?}
    
    J -->|NO| K[Error: Patr√≥n nombre incorrecto]
    J -->|S√ç| L[Elimina LibroRemuneracionesUpload previos]
    
    L --> M[Crea UploadLog con acci√≥n correccion]
    M --> N[Registra TarjetaActivityLog]
    N --> O[‚úÖ Retorna OK - Uploads eliminados]
    
    O --> P[Frontend: Llama onSubirArchivo]
    P --> Q[POST /cargar_libro_remuneraciones/]
    Q --> R[Analiza Headers]
    R --> S[Clasifica Columnas]
    S --> T[Procesa Registros]
    
    T --> U[Auto-dispara consolidarDatosTalana]
    U --> V[Consolidaci√≥n Modo Optimizado]
    
    V --> W{Hay Reconciliaci√≥n?}
    W -->|S√ç - reconciliacion.py| X[Recalcula Incidencias con Hash]
    W -->|NO - simple| Y[Crea Nuevas Incidencias]
    
    X --> Z[Compara Hash Estable]
    Z -->|Mismo Hash| AA[Actualiza Incidencia Existente]
    Z -->|Hash Diferente| AB[Crea Nueva Incidencia]
    Z -->|Hash No Encontrado| AC[Marca Anterior como Resuelta]
    
    AA --> AD[Actualiza: monto_actual, monto_anterior, version_detectada_ultima]
    AB --> AE[Nueva Incidencia con version_detectada_primera = vN]
    AC --> AF[Agrega ResolucionIncidencia tipo: desaparicion]
    
    Y --> AG[‚ö†Ô∏è Incidencias Duplicadas - Sin Control de Hash]
```

---

## üìù Detalles de Implementaci√≥n Actual

### 1. Endpoint de Correcci√≥n (`corregir_libro_view`)

**Ubicaci√≥n**: `backend/nomina/views_correcciones.py` l√≠nea 21

**Flujo**:
```python
def corregir_libro_view(request, cierre_id):
    # 1. Obtener archivo
    archivo = request.FILES.get('archivo')
    
    # 2. Validaciones
    - Validar extensi√≥n (.xlsx)
    - Validar tama√±o (< l√≠mite configurado)
    - Validar patr√≥n nombre: "{periodo}_libro_remuneraciones_{rut}.xlsx"
      Ejemplo: "202509_libro_remuneraciones_123456789.xlsx"
    
    # 3. Eliminar uploads previos
    libros_previos = LibroRemuneracionesUpload.objects.filter(cierre=cierre)
    for libro in libros_previos:
        libro.archivo.delete(save=False)  # Eliminar archivo f√≠sico
        libro.delete()  # Eliminar registro
    
    # 4. Crear UploadLog
    upload_log = crear_upload_log(
        tipo="libro_remuneraciones",
        accion="correccion_eliminacion_previos",
        resumen={
            "libros_previos_eliminados": count,
            "archivo_correccion_nombre": archivo.name
        }
    )
    
    # 5. Registrar actividad
    registrar_actividad_tarjeta_nomina(
        tarjeta="libro_remuneraciones",
        accion="correccion_eliminar_previos"
    )
    
    return {"message": "Validado", "eliminados": count}
```

**Caracter√≠sticas**:
- ‚úÖ NO incrementa `version_datos` (se hace al regenerar incidencias)
- ‚úÖ NO modifica datos consolidados
- ‚úÖ Solo elimina metadatos de uploads anteriores
- ‚úÖ Valida patr√≥n de nombre de archivo
- ‚ùå NO valida hash de archivo (no detecta si es id√©ntico)

### 2. Componente Frontend (`LibroRemuneracionesCardCorreccion`)

**Ubicaci√≥n**: `src/components/TarjetasCierreNomina/CorreccionLibro/LibroRemuneracionesCardCorreccion.jsx`

**Flujo**:
```javascript
const handleSeleccionArchivo = (archivo) => {
    setSelectedFile(archivo);
    setShowConfirmDelete(true);  // Muestra advertencia
};

const handleConfirmarCorreccion = async () => {
    // 1. Validar y eliminar previos
    await corregirLibroRemuneraciones(cierreId, selectedFile);
    
    // 2. Subir nuevo archivo
    await onSubirArchivo(selectedFile);
    
    // 3. Procesar (headers + clasificaci√≥n)
    await onProcesar();
    
    // 4. Auto-consolidar cuando estado = "procesado"
    await consolidarDatosTalana(cierreId, { modo: 'optimizado' });
};
```

**Estados del Archivo**:
- `no_subido` ‚Üí archivo no existe
- `analizando_hdrs` ‚Üí analizando columnas
- `clasif_pendiente` ‚Üí esperando clasificaci√≥n
- `clasificado` ‚Üí listo para procesar
- `procesando` ‚Üí procesando registros
- `procesado` ‚Üí ‚úÖ completo (dispara auto-consolidaci√≥n)

### 3. Sistema de Hash (Implementaci√≥n Actual)

**Hash de Incidencias** ‚úÖ:
```python
def generar_hash_deteccion(self):
    contenido = f"{self.cierre.id}|{self.concepto_afectado}|{self.tipo_incidencia}|{monto_actual}|{monto_anterior}"
    return hashlib.sha256(contenido).hexdigest()[:32]
```

**Hash Estable (Reconciliaci√≥n)** ‚úÖ:
```python
def _hash_incidencia_suma_total(nombre_concepto, tipo_concepto):
    """Hash que NO incluye montos, para identificar misma incidencia entre versiones"""
    base = f"suma_total|{tipo_concepto.lower()}|{nombre_concepto.lower()}"
    return hashlib.sha1(base.encode()).hexdigest()
```

**Hash de Archivo** ‚ùå (NO IMPLEMENTADO):
- NO se calcula hash del archivo libro remuneraciones
- NO se compara con versiones anteriores
- NO se detecta si el archivo es id√©ntico

---

## ‚ö†Ô∏è Problemas Actuales

### 1. **C√≥digo Legacy Sin Usar** (4 funciones obsoletas):
```python
# backend/nomina/views.py
def solicitar_recarga_archivos()  # L√≠nea 863 - NO USADO
def solicitar_recarga_archivos_analista()  # L√≠nea 948 - NO USADO
def aprobar_recarga_archivos()  # L√≠nea 989 - NO USADO

# backend/nomina/views_incidencias.py
def solicitar_recarga_archivos()  # L√≠nea 744 - NO USADO

# backend/nomina/views.py (ViewSet CierreNominaIncidencias)
def solicitar_recarga_archivos()  # L√≠nea 3106 - NO USADO
```

**Impacto**: C√≥digo muerto que confunde, aumenta complejidad y dificulta mantenimiento.

### 2. **Dos Sistemas de Generaci√≥n de Incidencias Compitiendo**:

#### A) Sistema Simplificado (DetectarIncidenciasConsolidadas.py):
```python
def procesar_incidencias_suma_total_simple():
    # ‚úÖ Genera hash correctamente (ya arreglado)
    # ‚ùå NO reconcilia con existentes
    # ‚ùå Puede crear duplicados al recargar
    # ‚ùå Usa bulk_create con ignore_conflicts
    
    for inc in incidencias_creadas:
        inc.hash_deteccion = inc.generar_hash_deteccion()
    IncidenciaCierre.objects.bulk_create(incidencias_creadas, ignore_conflicts=True)
```

**Problema**: El `ignore_conflicts` silencia errores pero NO actualiza existentes.

#### B) Sistema de Reconciliaci√≥n (reconciliacion.py):
```python
def reconciliar_cierre_suma_total():
    # ‚úÖ Upsert inteligente basado en hash estable
    # ‚úÖ Actualiza existentes o crea nuevas
    # ‚úÖ Marca desaparecidas como resueltas
    # ‚úÖ Maneja versiones correctamente
    
    hash_estable = _hash_incidencia_suma_total(nombre, tipo)
    existente = existentes_por_hash.get(hash_estable)
    if existente:
        # Actualizar campos cambiados
        existente.datos_adicionales = datos_nuevos
        existente.version_detectada_ultima = vN
        existente.save(update_fields=['datos_adicionales', 'version_detectada_ultima'])
    else:
        # Crear nueva
        IncidenciaCierre.objects.create(...)
```

**Problema**: Dependiendo de qu√© tarea Celery se ejecute, el comportamiento es diferente.

### 3. **Hash de Archivo NO Implementado**:
- ‚úÖ Existe `hash_deteccion` en incidencias
- ‚úÖ Existe `hash_archivo` en UploadLogNomina
- ‚ùå NO se calcula hash al corregir libro
- ‚ùå NO se compara con versi√≥n anterior
- ‚ùå Sistema puede reprocesar archivo id√©ntico innecesariamente

**Ejemplo del problema**:
```python
# Usuario sube mismo archivo por error
# Sistema:
1. Elimina uploads previos
2. Sube archivo id√©ntico
3. Procesa todo de nuevo (costoso)
4. Genera mismas incidencias
5. ‚ùå NO detecta que nada cambi√≥
```

### 4. **Versioning NO Sincronizado**:
- `CierreNomina.version_datos` ‚Üí NO se incrementa en correcci√≥n
- `IncidenciaCierre.version_detectada_primera` ‚Üí Se establece correctamente
- `IncidenciaCierre.version_detectada_ultima` ‚Üí Se establece correctamente
- ‚ùå Pero `version_datos` NO cambia, entonces versiones siempre son 1

**Problema**: El sistema de versiones no funciona porque `version_datos` nunca aumenta.

---

## ‚úÖ Propuesta de Refactorizaci√≥n

### Fase 1: Limpieza de C√≥digo Legacy

**Acci√≥n**: Eliminar c√≥digo obsoleto no usado

```python
# backend/nomina/views.py
# ‚ùå ELIMINAR:
- solicitar_recarga_archivos() l√≠nea 863
- solicitar_recarga_archivos_analista() l√≠nea 948  
- aprobar_recarga_archivos() l√≠nea 989

# backend/nomina/views_incidencias.py
# ‚ùå ELIMINAR:
- solicitar_recarga_archivos() l√≠nea 744

# backend/nomina/views.py (ViewSet CierreNominaIncidencias)
# ‚ùå ELIMINAR:
- solicitar_recarga_archivos() l√≠nea 3106
```

**Beneficio**: Reduce confusi√≥n, mejora claridad del c√≥digo.

### Fase 2: Unificar Sistema de Incidencias

**Opci√≥n A - Usar SOLO reconciliacion.py** (RECOMENDADO):

```python
# backend/nomina/utils/DetectarIncidenciasConsolidadas.py

def procesar_incidencias_suma_total_simple(cierre_actual, cierre_anterior):
    """
    DEPRECADO: Usar reconciliar_cierre_suma_total() en su lugar
    """
    from .reconciliacion import reconciliar_cierre_suma_total
    return reconciliar_cierre_suma_total(cierre_actual.id)
```

**Opci√≥n B - Mejorar sistema simplificado**:

```python
def procesar_incidencias_suma_total_simple(cierre_actual, cierre_anterior):
    # ... l√≥gica existente ...
    
    # NUEVO: Buscar incidencias existentes por hash
    existentes_por_hash = {}
    for inc in IncidenciaCierre.objects.filter(cierre=cierre_actual, tipo_comparacion='suma_total'):
        if inc.hash_deteccion:
            existentes_por_hash[inc.hash_deteccion] = inc
    
    # NUEVO: Upsert en lugar de bulk_create
    crear = []
    actualizar = []
    
    for inc_nueva in incidencias_creadas:
        inc_nueva.hash_deteccion = inc_nueva.generar_hash_deteccion()
        
        existente = existentes_por_hash.get(inc_nueva.hash_deteccion)
        if existente:
            # Actualizar existente
            existente.datos_adicionales = inc_nueva.datos_adicionales
            existente.impacto_monetario = inc_nueva.impacto_monetario
            existente.version_detectada_ultima = cierre_version
            actualizar.append(existente)
        else:
            # Crear nueva
            crear.append(inc_nueva)
    
    # Guardar cambios
    if actualizar:
        IncidenciaCierre.objects.bulk_update(
            actualizar,
            fields=['datos_adicionales', 'impacto_monetario', 'version_detectada_ultima']
        )
    if crear:
        IncidenciaCierre.objects.bulk_create(crear)
```

**Recomendaci√≥n**: Opci√≥n A (usar reconciliacion.py) porque:
- ‚úÖ Ya est√° probado y funcionando
- ‚úÖ Maneja desapariciones correctamente
- ‚úÖ Usa hash estable (sin montos)
- ‚úÖ Menos c√≥digo que mantener

### Fase 3: Implementar Validaci√≥n de Hash de Archivo

```python
# backend/nomina/views_correcciones.py

@api_view(['POST'])
def corregir_libro_view(request, cierre_id: int):
    archivo = request.FILES.get('archivo')
    cierre = CierreNomina.objects.get(id=cierre_id)
    
    # ... validaciones existentes ...
    
    # NUEVO: Calcular hash del archivo
    hash_nuevo = hashlib.md5()
    for chunk in archivo.chunks():
        hash_nuevo.update(chunk)
    hash_nuevo_hex = hash_nuevo.hexdigest()
    archivo.seek(0)  # Reset para procesamiento posterior
    
    # NUEVO: Comparar con √∫ltimo upload
    ultimo_upload = UploadLogNomina.objects.filter(
        cierre=cierre,
        tipo_upload='libro_remuneraciones',
        estado='completado'
    ).order_by('-fecha_subida').first()
    
    if ultimo_upload and ultimo_upload.hash_archivo == hash_nuevo_hex:
        return Response({
            "error": "El archivo es id√©ntico al anterior. No hay cambios para procesar.",
            "hash_anterior": ultimo_upload.hash_archivo,
            "hash_nuevo": hash_nuevo_hex,
            "fecha_anterior": ultimo_upload.fecha_subida
        }, status=400)
    
    # Continuar con flujo normal...
```

### Fase 4: Implementar Sistema de Versiones Correcto

```python
# backend/nomina/views_correcciones.py

def corregir_libro_view(request, cierre_id: int):
    # ... c√≥digo existente ...
    
    with transaction.atomic():
        cierre = CierreNomina.objects.select_for_update().get(id=cierre_id)
        
        # NUEVO: Incrementar versi√≥n al corregir
        cierre.version_datos = (cierre.version_datos or 1) + 1
        cierre.save(update_fields=['version_datos'])
        
        # Eliminar uploads previos...
        # Crear UploadLog con versi√≥n actualizada
        upload_log.resumen = {
            "accion": "correccion",
            "version_datos": cierre.version_datos,  # Nueva versi√≥n
            "hash_archivo": hash_nuevo_hex
        }
```

**Beneficio**: Ahora `version_detectada_primera` y `version_detectada_ultima` tienen valores significativos.

### Fase 5: Integrar TODO en el Flujo de Correcci√≥n

```python
# backend/nomina/views_correcciones.py

@api_view(['POST'])
def corregir_libro_view(request, cierre_id: int):
    """
    Flujo completo de correcci√≥n:
    1. Validar archivo (extensi√≥n, tama√±o, patr√≥n)
    2. Calcular hash y comparar con anterior
    3. Si es diferente: incrementar version_datos
    4. Eliminar uploads previos
    5. Retornar OK para que frontend proceda
    """
    # Implementaci√≥n completa arriba
```

**Resultado Final**:
```
Usuario ‚Üí Corregir Libro ‚Üí Validaci√≥n + Hash ‚Üí 
  Si diferente ‚Üí Incrementa version_datos ‚Üí Elimina previos ‚Üí 
  Frontend ‚Üí Sube archivo ‚Üí Procesa ‚Üí Consolida ‚Üí 
  reconciliar_cierre_suma_total() ‚Üí Upsert incidencias con hash estable
```

---

## ü§î Decisiones Necesarias

### 1. **¬øQu√© sistema de incidencias usar?**

**Opci√≥n A - reconciliar_cierre_suma_total()** ‚úÖ RECOMENDADO:
- Pros:
  * Ya probado y funcionando
  * Upsert inteligente (actualiza/crea/marca resueltas)
  * Hash estable sin montos
  * Maneja desapariciones
  * Menos c√≥digo que mantener
- Contras:
  * Depende de que `version_datos` se incremente correctamente

**Opci√≥n B - procesar_incidencias_suma_total_simple()** mejorado:
- Pros:
  * Control total del c√≥digo
  * M√°s simple de entender
- Contras:
  * Requiere agregar l√≥gica de upsert
  * Duplicaci√≥n de funcionalidad con reconciliacion.py
  * M√°s c√≥digo que mantener

**Recomendaci√≥n**: Opci√≥n A - migrar TODO a usar `reconciliar_cierre_suma_total()`.

### 2. **¬øValidar hash de archivo?**

**S√ç - Implementar validaci√≥n** ‚úÖ RECOMENDADO:
- Previene procesamiento innecesario
- Detecta errores del usuario (subi√≥ mismo archivo)
- Simple de implementar (solo calcular MD5 y comparar)
- Ahorra recursos de servidor

**NO - Dejar como est√°**:
- Usuario podr√≠a subir mismo archivo por error
- Sistema procesar√≠a todo de nuevo sin cambios
- Desperdicio de CPU y tiempo

**Recomendaci√≥n**: S√ç - validar hash en `corregir_libro_view()`.

### 3. **¬øIncrementar version_datos al corregir?**

**S√ç - Incrementar en corregir_libro_view()** ‚úÖ RECOMENDADO:
- Hace que el sistema de versiones funcione correctamente
- `version_detectada_primera` y `version_detectada_ultima` tienen sentido
- Permite rastrear evoluci√≥n de incidencias a trav√©s de correcciones
- Consistente con el dise√±o original del sistema

**NO - Incrementar solo al consolidar**:
- Sistema de versiones no funciona (siempre v1)
- No hay trazabilidad de correcciones

**Recomendaci√≥n**: S√ç - incrementar `version_datos` en `corregir_libro_view()`.

### 4. **¬øEliminar c√≥digo legacy?**

**S√ç - Eliminar** ‚úÖ RECOMENDADO:
- Reduce complejidad
- Evita confusi√≥n
- Mejora mantenibilidad
- Las funciones NO se usan en producci√≥n

**NO - Mantener por compatibilidad**:
- "Por si acaso" (pero nadie las llama)
- Aumenta deuda t√©cnica

**Recomendaci√≥n**: S√ç - eliminar todas las funciones `solicitar_recarga_archivos()` legacy.

---

## üéØ Plan de Acci√≥n Recomendado

### Paso 1: Actualizar corregir_libro_view() ‚úÖ PRIORIDAD ALTA
```python
# Agregar en views_correcciones.py:
1. Calcular hash del archivo
2. Comparar con √∫ltimo upload
3. Si diferente: incrementar version_datos
4. Eliminar uploads previos
5. Retornar con hash_archivo en respuesta
```

**Beneficio Inmediato**: 
- Sistema de versiones funciona
- Previene resubidas innecesarias

### Paso 2: Migrar a reconciliar_cierre_suma_total() ‚úÖ PRIORIDAD ALTA
```python
# En tasks_refactored/incidencias.py:
from nomina.utils.reconciliacion import reconciliar_cierre_suma_total

def generar_incidencias_con_logging(...):
    # Cambiar de:
    resultado = generar_incidencias_consolidados_v2(cierre_id, ...)
    # A:
    resultado = reconciliar_cierre_suma_total(cierre_id)
```

**Beneficio Inmediato**:
- Upsert correcto (no duplicados)
- Maneja desapariciones
- Versiones de incidencias correctas

### Paso 3: Eliminar c√≥digo legacy ‚úÖ PRIORIDAD MEDIA
```python
# Eliminar de views.py y views_incidencias.py:
- solicitar_recarga_archivos() (4 ubicaciones)
- aprobar_recarga_archivos() (1 ubicaci√≥n)
```

**Beneficio**: C√≥digo m√°s limpio, menos confusi√≥n.

### Paso 4: Actualizar documentaci√≥n ‚úÖ PRIORIDAD BAJA
- Actualizar `docs/reconciliacion_incidencias.md`
- Crear diagrama de flujo final simplificado
- Ejemplos de uso de "Corregir Libro"

**Beneficio**: Equipo entiende el flujo correcto.

---

## üìä Comparaci√≥n de Sistemas

| Aspecto | Sistema Actual | Sistema Propuesto |
|---------|---------------|-------------------|
| **Validaci√≥n Archivo** | ‚ùå NO valida hash | ‚úÖ Valida hash MD5 |
| **Versioning** | ‚ùå Siempre v1 | ‚úÖ Incrementa correctamente |
| **Upsert Incidencias** | ‚ùå ignore_conflicts | ‚úÖ Upsert inteligente |
| **Duplicados** | ‚ö†Ô∏è Posibles | ‚úÖ Imposibles |
| **Desapariciones** | ‚ùå No maneja | ‚úÖ Marca como resuelta |
| **C√≥digo Legacy** | ‚ùå 5 funciones sin usar | ‚úÖ Eliminadas |
| **Complejidad** | üî¥ Alta (2 sistemas) | üü¢ Baja (1 sistema) |
| **Mantenibilidad** | üî¥ Dif√≠cil | üü¢ F√°cil |

---

## üöÄ Implementaci√≥n R√°pida (MVP)

Si quieres implementar R√ÅPIDO con m√°ximo beneficio:

### Cambio #1: Incrementar version_datos (5 minutos)
```python
# En views_correcciones.py l√≠nea ~120
with transaction.atomic():
    cierre = CierreNomina.objects.select_for_update().get(id=cierre_id)
    cierre.version_datos = (cierre.version_datos or 1) + 1  # AGREGAR ESTA L√çNEA
    cierre.save(update_fields=['version_datos'])
```

### Cambio #2: Usar reconciliacion (5 minutos)
```python
# En tasks_refactored/incidencias.py l√≠nea ~260
# Cambiar de:
resultado = generar_incidencias_consolidados_v2(cierre_id, usuario_id)
# A:
from nomina.utils.reconciliacion import reconciliar_cierre_suma_total
resultado = reconciliar_cierre_suma_total(cierre_id)
```

**Resultado**: Sistema funcional con upsert correcto en 10 minutos.

---

## üìù Notas Finales

1. **No tocar consolidaci√≥n**: El flujo de consolidaci√≥n funciona bien, solo mejoramos la generaci√≥n de incidencias.

2. **Frontend no cambia**: El bot√≥n "Corregir Libro" sigue igual, solo mejoramos el backend.

3. **Backward compatible**: Los cambios no rompen funcionalidad existente.

4. **Testing**: Despu√©s de implementar, probar:
   - Corregir libro con archivo diferente ‚Üí debe crear/actualizar incidencias
   - Corregir libro con mismo archivo ‚Üí debe rechazar (despu√©s de implementar hash)
   - Verificar que `version_datos` incrementa correctamente
