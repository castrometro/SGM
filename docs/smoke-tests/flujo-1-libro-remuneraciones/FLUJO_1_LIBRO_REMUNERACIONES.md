# FLUJO 1: Procesamiento Completo de Libro de Remuneraciones

**Fecha**: 24 octubre 2025  
**Estado**: ğŸ“ EN DOCUMENTACIÃ“N - Smoke Test en progreso  
**PropÃ³sito**: Subir, clasificar y procesar archivo Excel con nÃ³mina mensual completa

---

## ğŸ“‹ Resumen Ejecutivo

- **Trigger**: Usuario sube archivo Excel desde el frontend
- **Pasos principales**: 
  1. Subir archivo
  2. Analizar headers automÃ¡ticamente
  3. Clasificar headers manualmente
  4. Procesar libro (crear empleados y conceptos)
- **DuraciÃ³n tÃ­pica**: 
  - Subida + AnÃ¡lisis: 5-10 segundos
  - ClasificaciÃ³n: Manual (1-2 minutos)
  - Procesamiento: 30-60 segundos
  - **Total**: ~2-3 minutos
- **Resultado**: Crea `EmpleadoCierre` y `RegistroConceptoEmpleado` en BD
- **PatrÃ³n**: Upload â†’ Task anÃ¡lisis â†’ UI clasificaciÃ³n â†’ Celery Chord paralelo

---

## ğŸ¯ PASO 1: Subir Archivo Excel

### 1.1 Frontend: SelecciÃ³n de Archivo
**Archivo**: `/src/components/TarjetasCierreNomina/LibroRemuneracionesCardConLogging.jsx`
**Archivo**: `/src/pages/CierreDetalleNomina.jsx`
```jsx
import CierreProgresoNomina from "../components/TarjetasCierreNomina/CierreProgresoNomina";

<CierreProgresoNomina
  cierre={cierre}
  cliente={cliente}
  onCierreActualizado={refrescarCierre}
/>
```

### 2. Componente de Progreso
**Archivo**: `/src/components/TarjetasCierreNomina/CierreProgresoNomina.jsx`

**Handler del botÃ³n** (lÃ­nea 545):
```javascript
const handleProcesarLibro = async () => {
  console.log('=== PROCESAR LIBRO ===');
  
  const id = libro?.id || libroId;
  
  // FORZAR el estado a "procesando" ANTES de la llamada
  setLibro(prev => ({
    ...prev,
    estado: "procesando"
  }));
  setLibroListo(false);
  
  await procesarLibroRemuneraciones(id);  // ğŸ‘ˆ LLAMADA A API
  console.log('âœ… Procesamiento iniciado - el polling monitorearÃ¡ el progreso');
}
```

**Estados locales**:
- `libro`: Objeto con datos del libro cargado
- `libroId`: ID del libro en BD
- `subiendo`: Boolean para mostrar spinner de carga
- `libroListo`: Boolean para habilitar/deshabilitar botÃ³n

---

## ğŸ“¡ Capa de API: Cliente HTTP

### 3. Cliente de API
**Archivo**: `/src/api/nomina.js` (lÃ­nea 767)

```javascript
export const procesarLibroRemuneraciones = async (libroId) => {
  const res = await api.post(
    `/nomina/libros-remuneraciones/${libroId}/procesar/`  // ğŸ‘ˆ ENDPOINT
  );
  return res.data;
};
```

**Request**:
```http
POST /api/nomina/libros-remuneraciones/{libroId}/procesar/
Content-Type: application/json
Authorization: Bearer {token}
```

**Response**:
```json
{
  "task_id": "abc-123-def-456",
  "mensaje": "Procesamiento optimizado iniciado (usando Celery Chord)",
  "optimizado": true
}
```

---

## ğŸ”— Backend: ViewSet

### 4. Vista de Django REST Framework
**Archivo**: `/backend/nomina/views.py` (lÃ­nea 1489)

**ViewSet**: `LibroRemuneracionesViewSet`  
**AcciÃ³n**: `@action(detail=True, methods=['post'])`

```python
def procesar(self, request, pk=None):
    """
    ğŸš€ Procesar libro completo: actualizar empleados y guardar registros.
    VersiÃ³n optimizada con Celery Chord para mejor rendimiento.
    """
    libro = self.get_object()
    libro.estado = 'procesando'
    libro.save(update_fields=['estado'])
    
    # Leer parÃ¡metros opcionales - optimizaciÃ³n activada por defecto
    usar_optimizacion = request.data.get('usar_optimizacion', True)
    
    logger.info(f"ğŸ”„ Iniciando procesamiento de libro {libro.id}")
    
    if usar_optimizacion:
        # ğŸš€ USAR VERSIONES OPTIMIZADAS CON CHORD
        result = chain(
            actualizar_empleados_desde_libro_optimizado.s(libro.id),  # ğŸ‘ˆ TASK 1
            guardar_registros_nomina_optimizado.s(),                   # ğŸ‘ˆ TASK 2
        ).apply_async()
        
        mensaje = 'Procesamiento optimizado iniciado'
    else:
        # ğŸ“ USAR VERSIONES CLÃSICAS
        result = chain(
            actualizar_empleados_desde_libro.s(libro.id),
            guardar_registros_nomina.s(),
        ).apply_async()
        mensaje = 'Procesamiento clÃ¡sico iniciado'
    
    return Response({
        'task_id': result.id,
        'mensaje': mensaje,
        'optimizado': usar_optimizacion
    }, status=status.HTTP_202_ACCEPTED)
```

**LÃ³gica de Negocio**:
1. âœ… Cambiar estado del libro a `'procesando'`
2. âœ… Decidir si usar versiÃ³n optimizada (por defecto: SÃ)
3. âœ… Crear Celery Chain con 2 tareas secuenciales
4. âœ… Retornar task_id para polling

---

## âš™ï¸ Celery Tasks: Procesamiento AsÃ­ncrono

### 5. Task Principal: Actualizar Empleados
**Archivo**: `/backend/nomina/tasks_refactored/libro_remuneraciones.py`

```python
@shared_task(bind=True, queue='nomina_queue')
def actualizar_empleados_desde_libro_optimizado(self, libro_id):
    """
    ğŸ“Š Fase 1: Crear/actualizar EmpleadoCierre con Celery Chord
    Divide empleados en chunks y los procesa en paralelo
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Leer Excel
    df = pd.read_excel(libro.archivo.path, sheet_name=0, dtype=str)
    
    # Obtener columnas de empleado
    columnas_empleado = ["rut", "nombre_completo", "cargo", etc...]
    df_empleados = df[columnas_empleado].drop_duplicates(subset=['rut'])
    
    # ğŸ”€ DIVIDIR EN CHUNKS PARA PROCESAMIENTO PARALELO
    CHUNK_SIZE = 10
    chunks = [
        df_empleados.iloc[i:i+CHUNK_SIZE]
        for i in range(0, len(df_empleados), CHUNK_SIZE)
    ]
    
    # ğŸ¼ CREAR CHORD: Procesar chunks en paralelo + consolidar
    job = chord(
        [
            procesar_chunk_empleados_task.s(
                chunk.to_dict('records'),
                libro_id,
                idx
            )
            for idx, chunk in enumerate(chunks)
        ]
    )(consolidar_empleados_task.s(libro_id))  # ğŸ‘ˆ CALLBACK
    
    return {
        'libro_id': libro_id,
        'total_empleados': len(df_empleados),
        'num_chunks': len(chunks),
        'job_id': job.id
    }
```

### 6. Subtask: Procesar Chunk de Empleados
```python
@shared_task(queue='nomina_queue')
def procesar_chunk_empleados_task(empleados_data, libro_id, chunk_idx):
    """
    ğŸ‘¥ Procesa un chunk de empleados en paralelo
    Cada worker procesa ~10 empleados simultÃ¡neamente
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    cierre = libro.cierre
    
    empleados_creados = []
    for emp_data in empleados_data:
        # Crear o actualizar EmpleadoCierre
        empleado, created = EmpleadoCierre.objects.update_or_create(
            cierre=cierre,
            rut=emp_data['rut'],
            defaults={
                'nombre_completo': emp_data['nombre_completo'],
                'cargo': emp_data.get('cargo'),
                'area': emp_data.get('area'),
                # ... otros campos
            }
        )
        empleados_creados.append(empleado.id)
    
    logger.info(f"âœ… Chunk {chunk_idx}: {len(empleados_creados)} empleados procesados")
    return empleados_creados
```

### 7. Callback: Consolidar Empleados
```python
@shared_task(queue='nomina_queue')
def consolidar_empleados_task(resultados_chunks, libro_id):
    """
    ğŸ”— Consolidar resultados de todos los chunks
    Se ejecuta cuando TODOS los chunks terminaron
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Aplanar lista de IDs
    todos_empleados = []
    for chunk_result in resultados_chunks:
        todos_empleados.extend(chunk_result)
    
    logger.info(f"âœ… ConsolidaciÃ³n: {len(todos_empleados)} empleados totales")
    
    return {
        'libro_id': libro_id,
        'empleados_ids': todos_empleados,
        'total': len(todos_empleados)
    }
```

### 8. Task Principal 2: Guardar Registros de Conceptos
```python
@shared_task(bind=True, queue='nomina_queue')
def guardar_registros_nomina_optimizado(self, resultado_empleados):
    """
    ğŸ’° Fase 2: Crear RegistroConceptoEmpleado con Celery Chord
    Procesa conceptos de nÃ³mina en paralelo por chunks
    """
    libro_id = resultado_empleados['libro_id']
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Leer Excel completo
    df = pd.read_excel(libro.archivo.path, sheet_name=0, dtype=str)
    
    # Obtener columnas de conceptos (excluyendo columnas de empleado)
    columnas_conceptos = [col for col in df.columns if col not in COLUMNAS_EMPLEADO]
    
    # ğŸ”€ DIVIDIR EN CHUNKS POR EMPLEADO
    CHUNK_SIZE = 10
    ruts_unicos = df['rut'].unique()
    chunks = [
        ruts_unicos[i:i+CHUNK_SIZE]
        for i in range(0, len(ruts_unicos), CHUNK_SIZE)
    ]
    
    # ğŸ¼ CREAR CHORD: Procesar registros en paralelo
    job = chord(
        [
            procesar_chunk_registros_task.s(
                chunk.tolist(),
                df[df['rut'].isin(chunk)].to_dict('records'),
                libro_id,
                idx
            )
            for idx, chunk in enumerate(chunks)
        ]
    )(consolidar_registros_task.s(libro_id))  # ğŸ‘ˆ CALLBACK FINAL
    
    return {
        'libro_id': libro_id,
        'total_registros_esperados': len(df) * len(columnas_conceptos),
        'job_id': job.id
    }
```

### 9. Subtask: Procesar Chunk de Registros
```python
@shared_task(queue='nomina_queue')
def procesar_chunk_registros_task(ruts_chunk, registros_data, libro_id, chunk_idx):
    """
    ğŸ’¸ Procesa registros de conceptos para un chunk de empleados
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    cierre = libro.cierre
    
    registros_creados = 0
    
    for registro in registros_data:
        rut = registro['rut']
        
        # Obtener empleado
        try:
            empleado = EmpleadoCierre.objects.get(cierre=cierre, rut=rut)
        except EmpleadoCierre.DoesNotExist:
            logger.warning(f"âš ï¸ Empleado {rut} no encontrado en chunk {chunk_idx}")
            continue
        
        # Crear registros de conceptos
        for concepto, valor in registro.items():
            if concepto in COLUMNAS_EMPLEADO:
                continue  # Saltar columnas de empleado
            
            if valor and str(valor).strip():
                RegistroConceptoEmpleado.objects.create(
                    empleado=empleado,
                    concepto=concepto,
                    valor=float(valor) if valor else 0,
                    periodo=cierre.periodo
                )
                registros_creados += 1
    
    logger.info(f"âœ… Chunk {chunk_idx}: {registros_creados} registros de conceptos creados")
    return registros_creados
```

### 10. Callback Final: Consolidar y Finalizar
```python
@shared_task(queue='nomina_queue')
def consolidar_registros_task(resultados_chunks, libro_id):
    """
    ğŸ‰ ConsolidaciÃ³n FINAL: Actualizar estado del libro
    Se ejecuta cuando TODO el procesamiento terminÃ³
    """
    libro = LibroRemuneracionesUpload.objects.get(id=libro_id)
    
    # Sumar todos los registros creados
    total_registros = sum(resultados_chunks)
    
    # âœ… ACTUALIZAR ESTADO FINAL
    libro.estado = 'procesado'
    libro.save(update_fields=['estado'])
    
    logger.info(f"ğŸ‰ Libro {libro_id} COMPLETADO: {total_registros} registros totales")
    
    return {
        'libro_id': libro_id,
        'estado_final': 'procesado',
        'total_registros': total_registros
    }
```

---

## ğŸ’¾ Modelos de Base de Datos

### Modelos Involucrados

#### 1. `LibroRemuneracionesUpload`
```python
# Estado cambia: 'clasificado' â†’ 'procesando' â†’ 'procesado'
{
    'id': 78,
    'cierre': ForeignKey(CierreNomina),
    'archivo': FileField,  # Excel subido
    'estado': 'procesado',
    'header_json': {...},  # Headers clasificados
    'fecha_upload': datetime
}
```

#### 2. `EmpleadoCierre`
```python
# Se crean/actualizan en Fase 1
{
    'id': 123,
    'cierre': ForeignKey(CierreNomina),
    'rut': '12345678-9',
    'nombre_completo': 'JUAN PEREZ',
    'cargo': 'ANALISTA',
    'area': 'OPERACIONES',
    'centro_costo': 'CC-100'
}
```

#### 3. `RegistroConceptoEmpleado`
```python
# Se crean en Fase 2
{
    'id': 456,
    'empleado': ForeignKey(EmpleadoCierre),
    'concepto': 'SUELDO BASE',
    'valor': 1500000.00,
    'periodo': '2025-10'
}
```

---

## ğŸ”„ Diagrama de Flujo Completo

```
USUARIO                    FRONTEND                    API                    BACKEND                    CELERY
  |                           |                        |                         |                          |
  | 1. Click "Procesar"       |                        |                         |                          |
  |-------------------------->|                        |                         |                          |
  |                           |                        |                         |                          |
  |                           | 2. POST /procesar/     |                         |                          |
  |                           |----------------------->|                         |                          |
  |                           |                        |                         |                          |
  |                           |                        | 3. ViewSet.procesar()   |                          |
  |                           |                        |------------------------>|                          |
  |                           |                        |                         |                          |
  |                           |                        |                         | 4. Chain.apply_async()   |
  |                           |                        |                         |------------------------->|
  |                           |                        |                         |                          |
  |                           | 5. Response task_id    |                         |                          |
  |                           |<-----------------------|                         |                          |
  |                           |                        |                         |                          |
  | 6. Polling cada 2s        |                        |                         |                          |
  |<------------------------->|                        |                         |                          |
  |                           |                        |                         |                          |
  |                           |                        |                         | 7. FASE 1: Empleados     |
  |                           |                        |                         |                          |
  |                           |                        |                         |   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>| Chunk 1 (10 emp)
  |                           |                        |                         |   | Chord paralelo       |
  |                           |                        |                         |   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>| Chunk 2 (10 emp)
  |                           |                        |                         |   |                      |
  |                           |                        |                         |   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>| Chunk N
  |                           |                        |                         |   |                      |
  |                           |                        |                         |   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|
  |                           |                        |                         |          â†“               |
  |                           |                        |                         |   Consolidar empleados   |
  |                           |                        |                         |<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|
  |                           |                        |                         |                          |
  |                           |                        |                         | 8. FASE 2: Conceptos     |
  |                           |                        |                         |                          |
  |                           |                        |                         |   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>| Chunk 1 (conceptos)
  |                           |                        |                         |   | Chord paralelo       |
  |                           |                        |                         |   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>| Chunk 2 (conceptos)
  |                           |                        |                         |   |                      |
  |                           |                        |                         |   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|
  |                           |                        |                         |          â†“               |
  |                           |                        |                         |   Consolidar registros   |
  |                           |                        |                         |<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|
  |                           |                        |                         |                          |
  |                           |                        |                         | 9. Estado = 'procesado'  |
  |                           |                        |                         |------------------------->|
  |                           |                        |                         |                          |
  | 10. Polling detecta       |                        |                         |                          |
  |     estado = 'procesado'  |                        |                         |                          |
  |<--------------------------|                        |                         |                          |
  |                           |                        |                         |                          |
  | 11. UI actualizada âœ…     |                        |                         |                          |
  |                           |                        |                         |                          |
```

---

## ğŸ“Š MÃ©tricas de Rendimiento

**Caso de prueba: Libro 78**
- Empleados: 62
- Conceptos por empleado: 48
- Registros totales: 2,976

**Tiempos**:
- Fase 1 (Empleados): ~10-15 segundos
- Fase 2 (Conceptos): ~20-30 segundos
- **Total**: ~35-45 segundos

**OptimizaciÃ³n con Chord**:
- Sin paralelizaciÃ³n: ~90 segundos
- Con paralelizaciÃ³n (10 chunks): ~40 segundos
- **Mejora**: 55% mÃ¡s rÃ¡pido

---

## âœ… Validaciones

1. **Pre-procesamiento**:
   - âœ… Libro debe estar en estado `'clasificado'`
   - âœ… Headers deben estar clasificados
   - âœ… Archivo Excel debe existir

2. **Durante procesamiento**:
   - âœ… RUT Ãºnico por empleado
   - âœ… Valores numÃ©ricos vÃ¡lidos para conceptos
   - âœ… Chunks se procesan sin overlapping

3. **Post-procesamiento**:
   - âœ… Todos los empleados creados
   - âœ… Todos los conceptos guardados
   - âœ… Estado actualizado correctamente

---

## âŒ Casos de Error

| Error | Causa | SoluciÃ³n |
|-------|-------|----------|
| `Libro no encontrado` | ID incorrecto | Verificar que libro existe |
| `Estado invÃ¡lido` | Libro ya procesado | Reprocesar solo si necesario |
| `Empleado duplicado` | RUT repetido en Excel | Limpiar datos de entrada |
| `Valor invÃ¡lido` | Concepto no numÃ©rico | Validar formato de columnas |
| `Chunk timeout` | Worker sobrecargado | Reducir CHUNK_SIZE |

---

## ğŸ”— Flujos Relacionados

- **Anterior**: FLUJO 0: Subir y Clasificar Headers
- **Siguiente**: FLUJO 5: Consolidar InformaciÃ³n
- **Depende de**: CierreNomina debe existir

---

## ğŸ§ª Resultados del Smoke Test

**Estado**: â³ PENDIENTE - Por probar

**Funciones utilizadas**:
- [ ] `actualizar_empleados_desde_libro_optimizado` âœ… Refactorizada
- [ ] `procesar_chunk_empleados_task` âœ… Refactorizada
- [ ] `consolidar_empleados_task` âœ… Refactorizada
- [ ] `guardar_registros_nomina_optimizado` âœ… Refactorizada
- [ ] `procesar_chunk_registros_task` âœ… Refactorizada
- [ ] `consolidar_registros_task` âœ… Refactorizada

**Stubs llamados**: (Se completarÃ¡ despuÃ©s de la prueba)

**Errores encontrados**: (Se completarÃ¡ despuÃ©s de la prueba)

---

**Documentado por**: GitHub Copilot  
**Ãšltima actualizaciÃ³n**: 24 octubre 2025
