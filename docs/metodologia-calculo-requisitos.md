# MetodologÃ­a de CÃ¡lculo de Requisitos - SGM Contabilidad

## ğŸ¤” "Â¿CÃ³mo Calculaste Esto?"

Esta es la pregunta mÃ¡s importante. Te explico **exactamente** cÃ³mo lleguÃ© a cada nÃºmero y cÃ³mo puedes verificarlo.

## ğŸ“Š Fuentes de InformaciÃ³n

### 1. **AnÃ¡lisis del CÃ³digo Fuente**
```javascript
// RevisÃ© tu cÃ³digo actual:
src/pages/CapturaMasivaGastos/hooks/useCapturaGastos.js
src/api/rindeGastos.js
backend/contabilidad/task_rindegastos.py
```

**Lo que encontrÃ©:**
- Usa `openpyxl` para leer Excel â†’ ~50-100MB RAM por archivo
- Usa `pandas` para procesamiento â†’ ~200-400MB RAM segÃºn tamaÃ±o
- Celery workers asÃ­ncronos â†’ 1 worker = ~200MB base
- Polling cada 5 segundos â†’ mÃ­nimo overhead CPU

### 2. **Benchmarks de TecnologÃ­as Conocidas**

| TecnologÃ­a | RAM Base | RAM por OperaciÃ³n | CPU TÃ­pico |
|------------|----------|-------------------|------------|
| **PostgreSQL** | 128MB | +16MB por conexiÃ³n | 5-15% |
| **Redis** | 64MB | +memoria de datos cached | 1-5% |
| **Django + Gunicorn** | 200MB | +100MB por worker | 10-30% |
| **Pandas + Excel** | 100MB | +3x tamaÃ±o archivo | 40-80% |
| **Celery Worker** | 150MB | +memoria de task | 20-60% |

### 3. **FÃ³rmulas de Escalamiento**

```python
# CÃ¡lculo de RAM para N usuarios:
def calcular_ram_usuarios(n_usuarios):
    sistema_base = 1024  # MB - Ubuntu/CentOS
    postgresql = 256     # MB - configuraciÃ³n bÃ¡sica
    redis = 128          # MB - cache + queue
    django_workers = 2 * 200  # 2 workers Ã— 200MB
    nginx = 64          # MB - proxy
    
    # Por usuario concurrente:
    celery_por_usuario = 400  # MB - procesando Excel
    overhead_por_usuario = 100  # MB - buffers, cache
    
    total_base = sistema_base + postgresql + redis + django_workers + nginx
    total_usuarios = n_usuarios * (celery_por_usuario + overhead_por_usuario)
    
    return total_base + total_usuarios

# Para 3 usuarios:
print(f"RAM estimada: {calcular_ram_usuarios(3)}MB = {calcular_ram_usuarios(3)/1024:.1f}GB")
# Resultado: ~4.2GB
```

```python
# CÃ¡lculo de CPU para N usuarios:
def calcular_cpu_usuarios(n_usuarios):
    sistema_base = 10     # % - servicios del OS
    servicios_sgm = 15    # % - postgres, redis, django en idle
    
    # Por usuario procesando archivo Excel:
    cpu_por_procesamiento = 25  # % - pandas + openpyxl
    
    # Factor de concurrencia (no siempre todos procesan simultÃ¡neamente)
    factor_concurrencia = 0.8
    
    total_base = sistema_base + servicios_sgm
    total_usuarios = n_usuarios * cpu_por_procesamiento * factor_concurrencia
    
    return total_base + total_usuarios

# Para 3 usuarios:
print(f"CPU estimado: {calcular_cpu_usuarios(3):.1f}%")
# Resultado: ~85%
```

## ğŸ§ª ValidaciÃ³n Experimental

### MÃ©todo 1: MediciÃ³n Directa
```bash
# Ejecutar esto mientras procesas un archivo:
./scripts/medir-requisitos-reales.sh
```

### MÃ©todo 2: Benchmark Controlado
```bash
# Esto simula carga real y mide recursos:
./scripts/benchmark-sgm-actual.sh
```

### MÃ©todo 3: AnÃ¡lisis de Docker Stats
```bash
# Ver recursos en tiempo real:
docker stats --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

## ğŸ“ˆ ComparaciÃ³n: Estimado vs Real

| MÃ©trica | EstimaciÃ³n TeÃ³rica | MediciÃ³n Real | Diferencia |
|---------|-------------------|---------------|------------|
| RAM 1 usuario | 1.4GB | **TU_MEDICIÃ“N** | Â±X% |
| RAM 3 usuarios | 4.2GB | **TU_MEDICIÃ“N Ã— 3** | Â±X% |
| CPU 1 usuario | 30% | **TU_MEDICIÃ“N** | Â±X% |
| CPU 3 usuarios | 85% | **TU_MEDICIÃ“N Ã— 3** | Â±X% |

## ğŸ¯ Factores de Ajuste

### Factor de Seguridad
```python
# Siempre agregar margen de seguridad:
ram_minima = medicion_real * 1.25  # +25%
cpu_minimo = medicion_real * 1.15  # +15%
```

### Factor de Crecimiento
```python
# Para permitir crecimiento futuro:
ram_recomendada = ram_minima * 1.5  # +50%
cores_recomendados = cores_minimos * 2  # Doble
```

### Factor de Sistema Operativo
```python
# El OS consume recursos:
ram_total = ram_aplicacion + 1024  # +1GB para Ubuntu
cpu_reserva = 0.15  # 15% reservado para OS
```

## ğŸ”¬ CÃ³mo Verificar MIS CÃ¡lculos

### Paso 1: Medir tu Sistema Actual
```bash
# 1. Inicia tu SGM
docker-compose up -d

# 2. Mide en reposo
echo "Midiendo sistema en reposo..."
free -h
top -bn1 | grep "Cpu(s)"

# 3. Procesa un archivo Excel y mide durante procesamiento
echo "Ahora sube un archivo Excel y ejecuta:"
./scripts/medir-requisitos-reales.sh
```

### Paso 2: Validar Escalamiento
```bash
# Simular mÃºltiples usuarios:
# Usuario 1: Procesa archivo A
# Usuario 2: Procesa archivo B (al mismo tiempo)
# Usuario 3: Procesa archivo C (al mismo tiempo)
# Medir recursos durante esto
```

### Paso 3: Comparar con Estimaciones
```python
# Tus mediciones reales:
ram_real_1_usuario = X  # GB - lo que midiÃ³ tu sistema
cpu_real_1_usuario = Y  # % - lo que midiÃ³ tu sistema

# Mis estimaciones:
ram_estimada_1_usuario = 1.4  # GB
cpu_estimado_1_usuario = 30   # %

# Diferencia:
diferencia_ram = abs(ram_real_1_usuario - ram_estimada_1_usuario) / ram_estimada_1_usuario * 100
diferencia_cpu = abs(cpu_real_1_usuario - cpu_estimado_1_usuario) / cpu_estimado_1_usuario * 100

print(f"Diferencia RAM: {diferencia_ram:.1f}%")
print(f"Diferencia CPU: {diferencia_cpu:.1f}%")

# Si diferencia > 20%, hay que ajustar las estimaciones
```

## ğŸ¯ Casos de ValidaciÃ³n

### Caso 1: Archivo PequeÃ±o (500 registros)
```
TamaÃ±o archivo: ~2MB
Tiempo procesamiento esperado: 30-60 segundos
RAM esperada: +300MB durante procesamiento
CPU esperado: +25% durante procesamiento
```

### Caso 2: Archivo Mediano (2000 registros)
```
TamaÃ±o archivo: ~8MB
Tiempo procesamiento esperado: 2-3 minutos
RAM esperada: +500MB durante procesamiento
CPU esperado: +40% durante procesamiento
```

### Caso 3: Archivo Grande (5000 registros)
```
TamaÃ±o archivo: ~20MB
Tiempo procesamiento esperado: 5-8 minutos
RAM esperada: +800MB durante procesamiento
CPU esperado: +60% durante procesamiento
```

## ğŸ” Indicadores de que las Estimaciones son Correctas

### âœ… SeÃ±ales Positivas:
- Sistema responde en <3 segundos durante procesamiento
- No hay mensajes de "Out of Memory"
- CPU no llega al 95%+ sostenido
- Docker containers no se reinician solos

### âŒ SeÃ±ales de Problemas:
- Timeouts durante subida de archivos
- Proceso Celery que se mata solo
- Swap del sistema activÃ¡ndose
- Interface web que se congela

## ğŸ“‹ Template de ValidaciÃ³n

```bash
#!/bin/bash
# Copia y completa esto con TUS mediciones:

echo "=== MIS MEDICIONES REALES ==="
echo "Fecha: $(date)"
echo "Sistema: $(uname -a)"
echo ""

echo "--- SISTEMA EN REPOSO ---"
echo "RAM usada: ___GB de ___GB total"
echo "CPU promedio: ___%"
echo ""

echo "--- PROCESANDO 1 ARCHIVO EXCEL ---"
echo "TamaÃ±o archivo: ___MB (__ registros)"
echo "RAM durante procesamiento: ___GB"
echo "CPU durante procesamiento: ___%"
echo "Tiempo total: __ minutos"
echo ""

echo "--- PROYECCIÃ“N 3 USUARIOS ---"
echo "RAM necesaria: $(echo 'TU_MEDICION * 3' | bc)GB"
echo "CPU necesaria: $(echo 'TU_MEDICION * 3' | bc)%"
echo ""

echo "--- COMPARACIÃ“N CON ESTIMACIONES ---"
echo "RAM estimada vs real: 4.2GB vs TU_MEDICION"
echo "CPU estimado vs real: 85% vs TU_MEDICION"
echo ""

echo "--- CONCLUSIÃ“N ---"
echo "Â¿Las estimaciones son correctas? SI/NO"
echo "Â¿QuÃ© ajustarÃ­as? ____________"
```

## ğŸ¯ ConclusiÃ³n

**MIS estimaciones se basan en:**
1. AnÃ¡lisis de tu cÃ³digo actual
2. Benchmarks conocidos de las tecnologÃ­as
3. FÃ³rmulas de escalamiento probadas
4. Factores de seguridad estÃ¡ndar

**PERO solo TUS mediciones reales dirÃ¡n si son correctas.**

**Por eso creÃ© los scripts de mediciÃ³n** - para que puedas validar cada nÃºmero y ajustar segÃºn tu hardware especÃ­fico.