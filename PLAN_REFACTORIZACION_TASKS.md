# ğŸ”¥ Plan de RefactorizaciÃ³n: nomina/tasks.py

**Fecha**: 17 de octubre de 2025  
**Problema**: Archivo monolÃ­tico de 5,279 lÃ­neas con 59 tareas Celery caÃ³ticas  
**Objetivo**: Organizar tareas por dominio funcional con estructura clara

---

## ğŸ“Š Estado Actual (AnÃ¡lisis)

### **NÃºmeros que Asustan**:
- **5,279 lÃ­neas** en un solo archivo
- **59 tareas Celery** (`@shared_task`)
- **~100+ funciones** totales
- **MÃºltiples versiones** de la misma funcionalidad:
  - `consolidar_datos_nomina_task()`
  - `consolidar_datos_nomina_task_optimizado()`
  - `consolidar_datos_nomina_task_secuencial()`
  - `consolidar_datos_nomina_task_paralelo()` (Â¿existe?)
- **CÃ³digo muerto**: v1, v2, _old, _legacy sin documentar
- **Sin organizaciÃ³n**: Todo mezclado sin separaciÃ³n por dominio

### **Tareas Identificadas por CategorÃ­a**:

#### ğŸ“– **Libro de Remuneraciones** (â‰ˆ15 tareas):
- `analizar_headers_libro_remuneraciones()`
- `analizar_headers_libro_remuneraciones_con_logging()` âš ï¸ DUPLICADO
- `clasificar_headers_libro_remuneraciones_task()`
- `clasificar_headers_libro_remuneraciones_con_logging()` âš ï¸ DUPLICADO
- `actualizar_empleados_desde_libro()`
- `guardar_registros_nomina()`
- `procesar_chunk_empleados_*()` (mÃºltiples versiones)
- `procesar_chunk_registros_*()` (mÃºltiples versiones)

#### ğŸ“… **Movimientos del Mes** (â‰ˆ3 tareas):
- `procesar_movimientos_mes()`
- `procesar_movimientos_personal_paralelo()`

#### ğŸ“‹ **Archivos Analista** (â‰ˆ2 tareas):
- `procesar_archivo_analista()`

#### ğŸ†• **Novedades** (â‰ˆ12 tareas):
- `analizar_headers_archivo_novedades()`
- `clasificar_headers_archivo_novedades_task()`
- `actualizar_empleados_desde_novedades_task()`
- `actualizar_empleados_desde_novedades_task_optimizado()` âš ï¸ DUPLICADO
- `guardar_registros_novedades_task()`
- `guardar_registros_novedades_task_optimizado()` âš ï¸ DUPLICADO
- `procesar_chunk_*_novedades_*()` (mÃºltiples)

#### ğŸ”„ **ConsolidaciÃ³n** (â‰ˆ10 tareas):
- `consolidar_cierre_task()`
- `consolidar_datos_nomina_task()`
- `consolidar_datos_nomina_task_optimizado()` âš ï¸ DUPLICADO
- `consolidar_datos_nomina_task_secuencial()` âš ï¸ DUPLICADO
- `procesar_empleados_libro_paralelo()`
- `procesar_conceptos_consolidados_paralelo()`
- `finalizar_consolidacion_post_movimientos()`
- `consolidar_resultados_finales()`

#### âš ï¸ **Incidencias** (â‰ˆ15 tareas):
- `generar_incidencias_totales_simple()`
- `generar_incidencias_cierre_task()`
- `generar_incidencias_consolidados_v2_task()` âš ï¸ v2
- `generar_incidencias_consolidadas_task()`
- `generar_incidencias_cierre_paralelo()`
- `procesar_chunk_comparacion_individual_task()`
- `procesar_comparacion_suma_total_task()`
- `consolidar_resultados_incidencias_task()`

#### ğŸ“‰ **Discrepancias** (â‰ˆ5 tareas):
- `analizar_datos_cierre_task()`
- `generar_discrepancias_cierre_task()`
- `generar_discrepancias_cierre_paralelo()`

---

## ğŸ¯ Estrategia de RefactorizaciÃ³n

### **Fase 1: Mapeo y DocumentaciÃ³n** (2 horas)
**Objetivo**: Entender quÃ© tareas se usan actualmente

#### Acciones:
1. **Identificar tareas activas**:
   ```bash
   # Buscar quÃ© tareas se llaman desde views
   grep -r "\.delay\|\.apply_async\|chain\|chord\|group" backend/nomina/views*.py
   ```

2. **Marcar cÃ³digo muerto**:
   - Tareas sin referencias: DEPRECATED
   - Versiones antiguas: OBSOLETE
   - Experimentos: EXPERIMENTAL

3. **Crear matriz de dependencias**:
   - Â¿QuÃ© tarea llama a quÃ©?
   - Â¿QuÃ© utils usa cada tarea?

### **Fase 2: Arquitectura Nueva** (DiseÃ±o)

#### **Estructura Propuesta**:

```
backend/nomina/
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ __init__.py              # Exporta todas las tareas para Celery
â”‚   â”‚
â”‚   â”œâ”€â”€ libro_remuneraciones.py  # ğŸ“– LIBRO DE REMUNERACIONES
â”‚   â”‚   â”œâ”€â”€ analizar_headers()
â”‚   â”‚   â”œâ”€â”€ clasificar_headers()
â”‚   â”‚   â”œâ”€â”€ procesar_empleados()
â”‚   â”‚   â”œâ”€â”€ procesar_registros()
â”‚   â”‚   â””â”€â”€ procesar_chunk_empleados()  # Worker paralelo
â”‚   â”‚
â”‚   â”œâ”€â”€ movimientos_mes.py       # ğŸ“… MOVIMIENTOS DEL MES
â”‚   â”‚   â”œâ”€â”€ procesar_movimientos()
â”‚   â”‚   â””â”€â”€ procesar_movimientos_paralelo()
â”‚   â”‚
â”‚   â”œâ”€â”€ archivos_analista.py     # ğŸ“‹ ARCHIVOS ANALISTA
â”‚   â”‚   â””â”€â”€ procesar_archivo()
â”‚   â”‚
â”‚   â”œâ”€â”€ novedades.py             # ğŸ†• NOVEDADES
â”‚   â”‚   â”œâ”€â”€ analizar_headers()
â”‚   â”‚   â”œâ”€â”€ clasificar_headers()
â”‚   â”‚   â”œâ”€â”€ procesar_empleados()
â”‚   â”‚   â””â”€â”€ procesar_registros()
â”‚   â”‚
â”‚   â”œâ”€â”€ consolidacion.py         # ğŸ”„ CONSOLIDACIÃ“N
â”‚   â”‚   â”œâ”€â”€ consolidar_cierre()
â”‚   â”‚   â”œâ”€â”€ consolidar_empleados()
â”‚   â”‚   â”œâ”€â”€ consolidar_conceptos()
â”‚   â”‚   â””â”€â”€ finalizar_consolidacion()
â”‚   â”‚
â”‚   â”œâ”€â”€ incidencias.py           # âš ï¸ INCIDENCIAS
â”‚   â”‚   â”œâ”€â”€ generar_incidencias_simple()
â”‚   â”‚   â”œâ”€â”€ generar_incidencias_avanzado()
â”‚   â”‚   â””â”€â”€ consolidar_incidencias()
â”‚   â”‚
â”‚   â”œâ”€â”€ discrepancias.py         # ğŸ“‰ DISCREPANCIAS
â”‚   â”‚   â”œâ”€â”€ analizar_datos_cierre()
â”‚   â”‚   â””â”€â”€ generar_discrepancias()
â”‚   â”‚
â”‚   â””â”€â”€ _deprecated.py           # ğŸ—‘ï¸ CÃ“DIGO OBSOLETO (temporal)
â”‚       â””â”€â”€ [todas las versiones antiguas]
â”‚
â””â”€â”€ tasks.py                     # âš ï¸ MANTENER VACÃO CON IMPORT
    # from .tasks import *  # Para retrocompatibilidad
```

#### **Ventajas**:
- âœ… **Modular**: Cada archivo < 500 lÃ­neas
- âœ… **Claro**: Nombre del archivo = dominio funcional
- âœ… **Mantenible**: FÃ¡cil encontrar dÃ³nde estÃ¡ cada tarea
- âœ… **Testeable**: Tests unitarios por mÃ³dulo
- âœ… **Escalable**: Agregar nuevas tareas sin contaminar

---

## ğŸ“‹ Plan de MigraciÃ³n (Paso a Paso)

### **Paso 1: Crear Estructura de Directorios**

```bash
mkdir -p backend/nomina/tasks
touch backend/nomina/tasks/__init__.py
```

### **Paso 2: Extraer Tareas por Dominio** (Orden de prioridad)

#### **2.1 Libro de Remuneraciones** (PRIMERO - crÃ­tico)

```python
# backend/nomina/tasks/libro_remuneraciones.py

from celery import shared_task, chain
from ..models import LibroRemuneracionesUpload, ActivityEvent
from ..utils.LibroRemuneraciones import (
    obtener_headers_libro_remuneraciones,
    clasificar_headers_libro_remuneraciones,
)
import logging

logger = logging.getLogger(__name__)

@shared_task(bind=True, queue='nomina_queue')
def analizar_headers(self, libro_id):
    """
    Analiza headers del libro de remuneraciones.
    
    Args:
        libro_id: ID del LibroRemuneracionesUpload
    
    Returns:
        dict: {libro_id, headers, archivo_path}
    
    Raises:
        Exception: Si falla el anÃ¡lisis
    """
    logger.info(f"[LIBRO] Analizando headers libro {libro_id}")
    
    try:
        libro = LibroRemuneracionesUpload.objects.select_related(
            'cierre', 'cierre__cliente'
        ).get(id=libro_id)
        
        cierre = libro.cierre
        
        # Logging V2
        ActivityEvent.log(
            user=sistema_user(),
            cliente=cierre.cliente,
            cierre=cierre,
            event_type='process',
            action='analisis_headers_iniciado',
            resource_type='libro_remuneraciones',
            resource_id=str(libro_id),
            details={'task_id': self.request.id}
        )
        
        # Procesar
        resultado = obtener_headers_libro_remuneraciones(
            str(libro.archivo.path)
        )
        
        # Logging Ã©xito
        ActivityEvent.log(
            user=sistema_user(),
            cliente=cierre.cliente,
            cierre=cierre,
            event_type='process',
            action='analisis_headers_exitoso',
            resource_type='libro_remuneraciones',
            resource_id=str(libro_id),
            details={
                'columnas': len(resultado['headers']),
                'task_id': self.request.id
            }
        )
        
        return {
            'libro_id': libro_id,
            'headers': resultado['headers'],
            'archivo_path': str(libro.archivo.path)
        }
        
    except Exception as e:
        logger.error(f"[LIBRO] Error analizando headers: {e}")
        
        # Logging error
        ActivityEvent.log(
            user=sistema_user(),
            cliente=cierre.cliente,
            cierre=cierre,
            event_type='process',
            action='analisis_headers_error',
            resource_type='libro_remuneraciones',
            resource_id=str(libro_id),
            details={'error': str(e)}
        )
        
        raise


@shared_task(bind=True, queue='nomina_queue')
def clasificar_headers(self, resultado_anterior):
    """
    Clasifica headers del libro usando IA.
    
    Args:
        resultado_anterior: Output de analizar_headers()
    
    Returns:
        dict: {libro_id, clasificaciones}
    """
    # Similar pattern...
    pass


def sistema_user():
    """Helper: Usuario sistema para Celery tasks"""
    from django.contrib.auth import get_user_model
    User = get_user_model()
    return User.objects.filter(is_staff=True).first()
```

#### **2.2 ConsolidaciÃ³n** (SEGUNDO - core business)

```python
# backend/nomina/tasks/consolidacion.py

@shared_task(bind=True, queue='nomina_queue')
def consolidar_cierre(self, cierre_id, modo='optimizado'):
    """
    Tarea principal de consolidaciÃ³n.
    
    Args:
        cierre_id: ID del CierreNomina
        modo: 'secuencial' | 'optimizado' | 'paralelo'
    """
    logger.info(f"[CONSOLIDACION] Iniciando modo={modo} cierre={cierre_id}")
    
    if modo == 'paralelo':
        return _consolidar_paralelo(cierre_id)
    elif modo == 'secuencial':
        return _consolidar_secuencial(cierre_id)
    else:
        return _consolidar_optimizado(cierre_id)


def _consolidar_optimizado(cierre_id):
    """ImplementaciÃ³n optimizada (default)"""
    # CÃ³digo limpio sin versiones antiguas
    pass


def _consolidar_paralelo(cierre_id):
    """ImplementaciÃ³n paralela con chord"""
    # Para cierres grandes (>10K registros)
    pass


def _consolidar_secuencial(cierre_id):
    """ImplementaciÃ³n secuencial (fallback)"""
    # Para debugging o cierres pequeÃ±os
    pass
```

#### **2.3 Incidencias** (TERCERO)

```python
# backend/nomina/tasks/incidencias.py

@shared_task(bind=True, queue='nomina_queue')
def generar_incidencias(self, cierre_id, tipo='simple'):
    """
    Genera incidencias para un cierre.
    
    Args:
        cierre_id: ID del CierreNomina
        tipo: 'simple' (umbral 30%) | 'avanzado' (comparaciÃ³n individual)
    """
    if tipo == 'simple':
        return _generar_simple(cierre_id)
    else:
        return _generar_avanzado(cierre_id)


def _generar_simple(cierre_id):
    """Umbral fijo 30% - rÃ¡pido"""
    pass


def _generar_avanzado(cierre_id):
    """ComparaciÃ³n individual por empleado - preciso"""
    pass
```

### **Paso 3: Actualizar `tasks/__init__.py`**

```python
# backend/nomina/tasks/__init__.py

"""
Celery tasks para el mÃ³dulo de nÃ³mina.

Estructura:
- libro_remuneraciones: Procesamiento de libros de remuneraciones
- movimientos_mes: Movimientos del mes
- consolidacion: ConsolidaciÃ³n de datos
- incidencias: GeneraciÃ³n de incidencias
- discrepancias: AnÃ¡lisis de discrepancias
"""

# Libro de Remuneraciones
from .libro_remuneraciones import (
    analizar_headers,
    clasificar_headers,
    procesar_empleados,
    procesar_registros,
)

# Movimientos del Mes
from .movimientos_mes import (
    procesar_movimientos,
)

# ConsolidaciÃ³n
from .consolidacion import (
    consolidar_cierre,
    consolidar_empleados,
    consolidar_conceptos,
)

# Incidencias
from .incidencias import (
    generar_incidencias,
)

# Discrepancias
from .discrepancias import (
    generar_discrepancias,
)

__all__ = [
    # Libro
    'analizar_headers',
    'clasificar_headers',
    'procesar_empleados',
    'procesar_registros',
    # Movimientos
    'procesar_movimientos',
    # ConsolidaciÃ³n
    'consolidar_cierre',
    'consolidar_empleados',
    'consolidar_conceptos',
    # Incidencias
    'generar_incidencias',
    # Discrepancias
    'generar_discrepancias',
]
```

### **Paso 4: Retrocompatibilidad en `tasks.py`**

```python
# backend/nomina/tasks.py

"""
âš ï¸ DEPRECATED: Este archivo se mantiene solo para retrocompatibilidad.
Nuevas tareas deben agregarse en nomina/tasks/

Las importaciones se hacen desde nomina.tasks.* directamente.
"""

# Importar todo desde el paquete tasks/
from .tasks import *  # noqa: F401, F403

# Este import permite que cÃ³digo legacy siga funcionando:
# from nomina.tasks import analizar_headers  # âœ… Funciona

# Advertencia en logs
import logging
logger = logging.getLogger(__name__)
logger.warning(
    "âš ï¸ Importando desde nomina.tasks (deprecated). "
    "Usa 'from nomina.tasks.libro_remuneraciones import analizar_headers' en su lugar."
)
```

### **Paso 5: Actualizar Views**

```python
# ANTES
from .tasks import analizar_headers_libro_remuneraciones_con_logging

# DESPUÃ‰S
from .tasks.libro_remuneraciones import analizar_headers

# O si prefieres mantener compatibilidad:
from .tasks import analizar_headers  # Funciona por el __init__.py
```

---

## ğŸ§ª Testing de la MigraciÃ³n

### **Verificar que Celery detecta las tareas**:

```bash
# Listar todas las tareas registradas
docker compose exec celery_worker celery -A sgm_backend inspect registered

# Debe aparecer:
# - nomina.tasks.libro_remuneraciones.analizar_headers
# - nomina.tasks.consolidacion.consolidar_cierre
# etc.
```

### **Test de importaciÃ³n**:

```python
# backend/test_imports_tasks.py

def test_imports_nuevos():
    """Verificar que los imports nuevos funcionan"""
    from nomina.tasks.libro_remuneraciones import analizar_headers
    from nomina.tasks.consolidacion import consolidar_cierre
    assert callable(analizar_headers)
    assert callable(consolidar_cierre)
    

def test_imports_legacy():
    """Verificar retrocompatibilidad"""
    from nomina.tasks import analizar_headers
    assert callable(analizar_headers)
```

---

## ğŸ“ Convenciones de CÃ³digo

### **Naming**:
- Tareas: `verbo_sustantivo()` â†’ `analizar_headers()`, `consolidar_cierre()`
- No sufijos: `_task`, `_con_logging`, `_optimizado` (elegir UNA versiÃ³n)
- Helpers privados: `_helper_name()` â†’ `_consolidar_paralelo()`

### **Docstrings**:
```python
@shared_task(bind=True, queue='nomina_queue')
def analizar_headers(self, libro_id):
    """
    Breve descripciÃ³n de una lÃ­nea.
    
    Args:
        libro_id: DescripciÃ³n del parÃ¡metro
    
    Returns:
        dict: Estructura del resultado
    
    Raises:
        Exception: CuÃ¡ndo falla
    
    Example:
        >>> result = analizar_headers.delay(123)
        >>> result.get()
        {'libro_id': 123, 'headers': [...]}
    """
```

### **Logging consistente**:
```python
logger.info(f"[{DOMINIO}] Mensaje claro")
logger.error(f"[{DOMINIO}] Error: {e}", exc_info=True)

# Ejemplos:
# [LIBRO] Analizando headers libro 123
# [CONSOLIDACION] Iniciando modo=paralelo cierre=30
# [INCIDENCIAS] Generadas 5 incidencias para cierre 30
```

### **ActivityEvent siempre**:
```python
# Inicio de tarea
ActivityEvent.log(
    user=sistema_user(),
    cliente=cierre.cliente,
    cierre=cierre,
    event_type='process',
    action='operacion_iniciada',
    resource_type='tipo_recurso',
    resource_id=str(recurso_id),
    details={'task_id': self.request.id}
)

# Ã‰xito
ActivityEvent.log(..., action='operacion_exitosa', details={'resultado': stats})

# Error
ActivityEvent.log(..., action='operacion_error', details={'error': str(e)})
```

---

## ğŸ—‘ï¸ CÃ³digo a Eliminar (Deprecation Plan)

### **Marcar como deprecated**:
```python
# backend/nomina/tasks/_deprecated.py

import warnings

@shared_task
def analizar_headers_libro_remuneraciones_con_logging(libro_id, upload_log_id):
    """
    âš ï¸ DEPRECATED: Usar nomina.tasks.libro_remuneraciones.analizar_headers
    
    Esta tarea se eliminarÃ¡ en la versiÃ³n 2.0.0
    """
    warnings.warn(
        "analizar_headers_libro_remuneraciones_con_logging estÃ¡ deprecated. "
        "Usa nomina.tasks.libro_remuneraciones.analizar_headers",
        DeprecationWarning,
        stacklevel=2
    )
    
    # Redirigir a la nueva tarea
    from .libro_remuneraciones import analizar_headers
    return analizar_headers.delay(libro_id)
```

### **Timeline de eliminaciÃ³n**:
1. **Semana 1-2**: Migrar todas las llamadas en views
2. **Semana 3-4**: Marcar tareas antiguas como deprecated
3. **Mes 2**: Eliminar tareas deprecated si no hay uso

---

## ğŸ“Š ComparaciÃ³n Antes/DespuÃ©s

| MÃ©trica | ANTES | DESPUÃ‰S |
|---------|-------|---------|
| **Archivo principal** | 5,279 lÃ­neas | ~50 lÃ­neas (imports) |
| **Tareas totales** | 59 tareas | ~25 tareas (limpiado) |
| **Versiones duplicadas** | 3-4 por funcionalidad | 1 por funcionalidad |
| **Archivos** | 1 monolito | 7 mÃ³dulos especializados |
| **Mantenibilidad** | âŒ Imposible | âœ… Alta |
| **Testeable** | âŒ DifÃ­cil | âœ… FÃ¡cil (por mÃ³dulo) |
| **Onboarding** | 2 dÃ­as | 2 horas |

---

## ğŸš€ Prioridades de ImplementaciÃ³n

### **Prioridad 1 (CRÃTICO)**: Libro de Remuneraciones
- **RazÃ³n**: Es el flujo principal del sistema
- **Impacto**: Alto - se usa en cada cierre
- **Esfuerzo**: 3-4 horas
- **Archivos afectados**: 
  - `views_libro_remuneraciones.py`
  - Tests de libro

### **Prioridad 2 (IMPORTANTE)**: ConsolidaciÃ³n
- **RazÃ³n**: Core business logic
- **Impacto**: Alto - afecta reportes
- **Esfuerzo**: 4-5 horas
- **DecisiÃ³n clave**: Â¿QuÃ© modo es el default? (optimizado vs paralelo)

### **Prioridad 3 (MEDIO)**: Incidencias
- **RazÃ³n**: Feature complejo con mÃºltiples versiones
- **Impacto**: Medio - solo para revisiÃ³n
- **Esfuerzo**: 3-4 horas

### **Prioridad 4 (BAJO)**: Movimientos, Analista, Novedades
- **RazÃ³n**: Menos usados
- **Impacto**: Bajo
- **Esfuerzo**: 2 horas c/u

---

## âœ… Checklist de RefactorizaciÃ³n

### **PlanificaciÃ³n**:
- [ ] Mapear todas las tareas activas (grep en views)
- [ ] Identificar dependencias entre tareas
- [ ] Decidir quÃ© versiones mantener (optimizado vs secuencial vs paralelo)
- [ ] Documentar cÃ³digo muerto

### **ImplementaciÃ³n**:
- [ ] Crear estructura `nomina/tasks/`
- [ ] Migrar libro_remuneraciones.py (PRIMERO)
- [ ] Actualizar views para usar nuevos imports
- [ ] Verificar Celery detecta las tareas
- [ ] Tests de imports

### **Limpieza**:
- [ ] Mover cÃ³digo obsoleto a `_deprecated.py`
- [ ] Marcar tareas antiguas con warnings
- [ ] Eliminar versiones duplicadas
- [ ] Reducir `tasks.py` a solo imports

### **ValidaciÃ³n**:
- [ ] Subir libro â†’ Verificar task ejecuta
- [ ] Consolidar cierre â†’ Verificar task ejecuta
- [ ] Generar incidencias â†’ Verificar task ejecuta
- [ ] Revisar logs de Celery (sin errores)
- [ ] ActivityEvent registra eventos correctamente

---

## ğŸ¯ Resultado Final Esperado

```bash
backend/nomina/tasks/
â”œâ”€â”€ __init__.py                    # 50 lÃ­neas (exports)
â”œâ”€â”€ libro_remuneraciones.py        # 400 lÃ­neas
â”œâ”€â”€ movimientos_mes.py             # 150 lÃ­neas
â”œâ”€â”€ archivos_analista.py           # 100 lÃ­neas
â”œâ”€â”€ novedades.py                   # 300 lÃ­neas
â”œâ”€â”€ consolidacion.py               # 500 lÃ­neas
â”œâ”€â”€ incidencias.py                 # 300 lÃ­neas
â”œâ”€â”€ discrepancias.py               # 200 lÃ­neas
â””â”€â”€ _deprecated.py                 # 500 lÃ­neas (temporal)

Total: ~2,500 lÃ­neas (vs 5,279 original)
ReducciÃ³n: 52% de cÃ³digo
```

**Beneficios**:
- âœ… CÃ³digo limpio y organizado
- âœ… FÃ¡cil de mantener
- âœ… FÃ¡cil de testear
- âœ… FÃ¡cil de entender para nuevos devs
- âœ… Sin versiones duplicadas
- âœ… Logging consistente
- âœ… ActivityEvent integrado

---

## â±ï¸ EstimaciÃ³n de Tiempo

| Fase | Tiempo | DescripciÃ³n |
|------|--------|-------------|
| **Mapeo** | 2h | Analizar cÃ³digo actual |
| **Libro** | 4h | Migrar libro_remuneraciones.py |
| **ConsolidaciÃ³n** | 5h | Migrar consolidacion.py |
| **Incidencias** | 4h | Migrar incidencias.py |
| **Resto** | 4h | Movimientos, analista, novedades |
| **Testing** | 3h | Verificar todo funciona |
| **Limpieza** | 2h | Deprecated y documentaciÃ³n |
| **TOTAL** | **24h** | ~3 dÃ­as de trabajo |

---

## ğŸ¤” Decisiones Pendientes

1. **Â¿QuÃ© versiÃ³n de consolidaciÃ³n es la "buena"?**
   - `optimizado` â†’ Default
   - `paralelo` â†’ Para cierres grandes
   - `secuencial` â†’ Deprecated

2. **Â¿Eliminamos cÃ³digo muerto inmediatamente?**
   - OpciÃ³n A: Mover a `_deprecated.py` con warnings
   - OpciÃ³n B: Eliminar directamente (agresivo)
   - **RecomendaciÃ³n**: OpciÃ³n A (mÃ¡s seguro)

3. **Â¿CÃ³mo manejamos las versiones "con_logging"?**
   - **SoluciÃ³n**: TODAS las tareas nuevas tienen logging integrado
   - Eliminar sufijo `_con_logging`

4. **Â¿Tasks con sufijo `_task`?**
   - **SoluciÃ³n**: Eliminar sufijo (redundante)
   - `clasificar_headers_task()` â†’ `clasificar_headers()`

---

## ğŸ¯ Â¿Empezamos?

**Propongo**:
1. **AHORA**: Mapear tareas activas (2h)
2. **HOY**: Migrar `libro_remuneraciones.py` (4h)
3. **MAÃ‘ANA**: Resto de mÃ³dulos (8h)

**Â¿Confirmas el plan?** ğŸš€
