"""
Sistema de cache Redis para SGM - Contabilidad
==============================================

Estructura de cache:
sgm:contabilidad:{cliente_id}:{periodo}/
‚îú‚îÄ‚îÄ kpis
‚îú‚îÄ‚îÄ procesamiento
‚îú‚îÄ‚îÄ alertas
‚îú‚îÄ‚îÄ esf (Estado de Situaci√≥n Financiera)
‚îú‚îÄ‚îÄ esr (Estado de Resultados)
‚îú‚îÄ‚îÄ eri (Estado de Resultados Integral)
‚îú‚îÄ‚îÄ ecp (Estado de Cambios en el Patrimonio)
‚îú‚îÄ‚îÄ movimientos
‚îú‚îÄ‚îÄ cuentas
‚îî‚îÄ‚îÄ pruebas (Datos de prueba y testing)

Autor: Sistema SGM
Fecha: 8 de julio de 2025
"""

import redis
import json
import logging
from datetime import datetime, timedelta
from django.conf import settings
from typing import Dict, Any, Optional, List, Union

# Configurar logging
logger = logging.getLogger(__name__)

class SGMCacheSystem:
    """Sistema de cache Redis para SGM - Contabilidad"""
    
    def __init__(self):
        """Inicializar conexi√≥n a Redis DB 1 (contabilidad)"""
        try:
            self.redis_client = redis.Redis(
                host='redis',
                port=6379,
                db=1,  # DB 1 dedicada para contabilidad
                password=getattr(settings, 'REDIS_PASSWORD', ''),
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True
            )
            
            # Verificar conexi√≥n
            if not self.redis_client.ping():
                raise redis.ConnectionError("No se pudo conectar a Redis")
                
            logger.info("SGM Cache System inicializado correctamente en Redis DB 1")
            
        except Exception as e:
            logger.error(f"Error inicializando SGM Cache System: {e}")
            raise
        
        # Configuraci√≥n de TTL por defecto
        self.default_ttl = 3600  # 1 hora
        self.long_ttl = 14400    # 4 horas para datos estables
        self.short_ttl = 300     # 5 minutos para datos temporales
        
    def _get_key(self, cliente_id: int, periodo: str, tipo_dato: str) -> str:
        """
        Generar clave Redis siguiendo el patr√≥n del sistema SGM
        Formato: sgm:contabilidad:{cliente_id}:{periodo}:{tipo_dato}
        """
        return f"sgm:contabilidad:{cliente_id}:{periodo}:{tipo_dato}"
    
    def _serialize_data(self, data: Any) -> str:
        """Serializar datos para almacenar en Redis"""
        try:
            return json.dumps(data, ensure_ascii=False, default=str)
        except Exception as e:
            logger.error(f"Error serializando datos: {e}")
            raise
    
    def _deserialize_data(self, data: str) -> Any:
        """Deserializar datos desde Redis"""
        try:
            return json.loads(data)
        except Exception as e:
            logger.error(f"Error deserializando datos: {e}")
            raise
    
    # ========== KPIs ==========
    def set_kpis(self, cliente_id: int, periodo: str, kpis: Dict[str, Any], ttl: int = None) -> bool:
        """
        Guardar KPIs del cliente/periodo
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable (ej: "2025-07")
            kpis: Diccionario con KPIs calculados
            ttl: Tiempo de vida en segundos (opcional)
        
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, "kpis")
        ttl = ttl or self.default_ttl
        
        try:
            # Agregar metadata
            kpis_with_meta = {
                **kpis,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'kpis'
                }
            }
            
            serialized_data = self._serialize_data(kpis_with_meta)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("kpis_cached")
            
            logger.info(f"KPIs guardados en cache: cliente={cliente_id}, periodo={periodo}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando KPIs: {e}")
            return False
    
    def get_kpis(self, cliente_id: int, periodo: str) -> Optional[Dict[str, Any]]:
        """
        Obtener KPIs del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            Dict con KPIs o None si no existe en cache
        """
        key = self._get_key(cliente_id, periodo, "kpis")
        
        try:
            data = self.redis_client.get(key)
            if data:
                kpis = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("kpis_retrieved")
                
                logger.debug(f"KPIs obtenidos del cache: cliente={cliente_id}, periodo={periodo}")
                return kpis
            else:
                self._increment_stat("cache_misses")
                logger.debug(f"KPIs no encontrados en cache: cliente={cliente_id}, periodo={periodo}")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo KPIs: {e}")
            self._increment_stat("cache_errors")
            return None
    
    # ========== Estados Financieros ==========
    def set_estado_financiero(self, cliente_id: int, periodo: str, tipo_estado: str, 
                             datos: Dict[str, Any], ttl: int = None) -> bool:
        """
        Guardar estado financiero (ESF, ESR, ERI, ECP)
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            tipo_estado: Tipo de estado ('esf', 'esr', 'eri', 'ecp')
            datos: Datos del estado financiero
            ttl: Tiempo de vida en segundos
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        # Validar tipo de estado
        estados_validos = ['esf', 'esr', 'eri', 'ecp']
        if tipo_estado not in estados_validos:
            raise ValueError(f"Tipo de estado inv√°lido: {tipo_estado}. V√°lidos: {estados_validos}")
            
        key = self._get_key(cliente_id, periodo, tipo_estado)
        ttl = ttl or self.long_ttl  # Estados financieros con mayor TTL
        
        try:
            # Agregar metadata espec√≠fica para estados financieros
            datos_with_meta = {
                **datos,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'tipo_estado': tipo_estado,
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'estado_financiero'
                }
            }
            
            serialized_data = self._serialize_data(datos_with_meta)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat(f"{tipo_estado}_cached")
            
            logger.info(f"Estado financiero {tipo_estado.upper()} guardado: cliente={cliente_id}, periodo={periodo}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando estado {tipo_estado}: {e}")
            return False
    
    def get_estado_financiero(self, cliente_id: int, periodo: str, tipo_estado: str) -> Optional[Dict[str, Any]]:
        """
        Obtener estado financiero del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            tipo_estado: Tipo de estado ('esf', 'esr', 'eri', 'ecp')
            
        Returns:
            Dict con datos del estado o None si no existe
        """
        key = self._get_key(cliente_id, periodo, tipo_estado)
        
        try:
            data = self.redis_client.get(key)
            if data:
                estado = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat(f"{tipo_estado}_retrieved")
                
                logger.debug(f"Estado {tipo_estado.upper()} obtenido del cache: cliente={cliente_id}, periodo={periodo}")
                return estado
            else:
                self._increment_stat("cache_misses")
                logger.debug(f"Estado {tipo_estado.upper()} no encontrado en cache: cliente={cliente_id}, periodo={periodo}")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo estado {tipo_estado}: {e}")
            self._increment_stat("cache_errors")
            return None
    
    # ========== Procesamiento ==========
    def set_procesamiento_status(self, cliente_id: int, periodo: str, status: Dict[str, Any]) -> bool:
        """
        Guardar estado de procesamiento (datos temporales)
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            status: Estado del procesamiento
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, "procesamiento")
        
        try:
            status_with_meta = {
                **status,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'updated_at': datetime.now().isoformat(),
                    'ttl': self.short_ttl,
                    'tipo': 'procesamiento'
                }
            }
            
            serialized_data = self._serialize_data(status_with_meta)
            # Procesamiento con TTL corto (5 minutos)
            self.redis_client.setex(key, self.short_ttl, serialized_data)
            
            self._increment_stat("procesamiento_updates")
            
            logger.debug(f"Estado de procesamiento actualizado: cliente={cliente_id}, periodo={periodo}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando procesamiento: {e}")
            return False
    
    def get_procesamiento_status(self, cliente_id: int, periodo: str) -> Optional[Dict[str, Any]]:
        """
        Obtener estado de procesamiento
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            Dict con estado de procesamiento o None
        """
        key = self._get_key(cliente_id, periodo, "procesamiento")
        
        try:
            data = self.redis_client.get(key)
            if data:
                status = self._deserialize_data(data)
                logger.debug(f"Estado de procesamiento obtenido: cliente={cliente_id}, periodo={periodo}")
                return status
            return None
            
        except Exception as e:
            logger.error(f"Error obteniendo procesamiento: {e}")
            return None
    
    # ========== Alertas ==========
    def set_alertas(self, cliente_id: int, periodo: str, alertas: List[Dict[str, Any]]) -> bool:
        """
        Guardar alertas del periodo
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            alertas: Lista de alertas
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, "alertas")
        
        try:
            alertas_with_meta = {
                'alertas': alertas,
                'count': len(alertas),
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'created_at': datetime.now().isoformat(),
                    'ttl': self.default_ttl,
                    'tipo': 'alertas'
                }
            }
            
            serialized_data = self._serialize_data(alertas_with_meta)
            self.redis_client.setex(key, self.default_ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("alertas_cached")
            
            logger.info(f"Alertas guardadas en cache: cliente={cliente_id}, periodo={periodo}, count={len(alertas)}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando alertas: {e}")
            return False
    
    def get_alertas(self, cliente_id: int, periodo: str) -> Optional[List[Dict[str, Any]]]:
        """
        Obtener alertas del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            Lista de alertas o None
        """
        key = self._get_key(cliente_id, periodo, "alertas")
        
        try:
            data = self.redis_client.get(key)
            if data:
                alertas_data = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("alertas_retrieved")
                
                logger.debug(f"Alertas obtenidas del cache: cliente={cliente_id}, periodo={periodo}")
                return alertas_data.get('alertas', [])
            else:
                self._increment_stat("cache_misses")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo alertas: {e}")
            return None
    
    # ========== Movimientos ==========
    def set_movimientos(self, cliente_id: int, periodo: str, movimientos: List[Dict[str, Any]], 
                       ttl: int = None) -> bool:
        """
        Guardar movimientos del periodo
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            movimientos: Lista de movimientos contables
            ttl: Tiempo de vida en segundos
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, "movimientos")
        ttl = ttl or self.default_ttl
        
        try:
            movimientos_with_meta = {
                'movimientos': movimientos,
                'count': len(movimientos),
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'movimientos'
                }
            }
            
            serialized_data = self._serialize_data(movimientos_with_meta)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("movimientos_cached")
            
            logger.info(f"Movimientos guardados en cache: cliente={cliente_id}, periodo={periodo}, count={len(movimientos)}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando movimientos: {e}")
            return False
    
    def get_movimientos(self, cliente_id: int, periodo: str) -> Optional[List[Dict[str, Any]]]:
        """
        Obtener movimientos del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            Lista de movimientos o None
        """
        key = self._get_key(cliente_id, periodo, "movimientos")
        
        try:
            data = self.redis_client.get(key)
            if data:
                movimientos_data = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("movimientos_retrieved")
                
                logger.debug(f"Movimientos obtenidos del cache: cliente={cliente_id}, periodo={periodo}")
                return movimientos_data.get('movimientos', [])
            else:
                self._increment_stat("cache_misses")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo movimientos: {e}")
            return None
    
    # ========== Cuentas ==========
    def set_cuentas(self, cliente_id: int, periodo: str, cuentas: Dict[str, Any], 
                   ttl: int = None) -> bool:
        """
        Guardar cat√°logo de cuentas
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            cuentas: Diccionario con cat√°logo de cuentas
            ttl: Tiempo de vida en segundos
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, "cuentas")
        ttl = ttl or self.long_ttl  # Cuentas son datos m√°s estables
        
        try:
            cuentas_with_meta = {
                **cuentas,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'cuentas'
                }
            }
            
            serialized_data = self._serialize_data(cuentas_with_meta)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("cuentas_cached")
            
            logger.info(f"Cuentas guardadas en cache: cliente={cliente_id}, periodo={periodo}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando cuentas: {e}")
            return False
    
    def get_cuentas(self, cliente_id: int, periodo: str) -> Optional[Dict[str, Any]]:
        """
        Obtener cat√°logo de cuentas del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            Dict con cat√°logo de cuentas o None
        """
        key = self._get_key(cliente_id, periodo, "cuentas")
        
        try:
            data = self.redis_client.get(key)
            if data:
                cuentas = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("cuentas_retrieved")
                
                logger.debug(f"Cuentas obtenidas del cache: cliente={cliente_id}, periodo={periodo}")
                return cuentas
            else:
                self._increment_stat("cache_misses")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo cuentas: {e}")
            return None
    
    # ========== Pruebas y Testing ==========
    def set_prueba_esf(self, cliente_id: int, periodo: str, esf_data: Dict[str, Any], 
                       test_type: str = "current_system", ttl: int = None) -> bool:
        """
        Guardar ESF de prueba generado por el sistema actual
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            esf_data: Datos del ESF generado por el sistema
            test_type: Tipo de prueba ("current_system", "manual", "testing")
            ttl: Tiempo de vida en segundos
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        # Usar subclave para organizar diferentes tipos de pruebas
        key = self._get_key(cliente_id, periodo, f"pruebas:esf:{test_type}")
        ttl = ttl or self.default_ttl
        
        try:
            # Agregar metadata espec√≠fica para pruebas
            prueba_data = {
                **esf_data,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'test_type': test_type,
                    'source': 'sistema_actual',
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'prueba_esf'
                }
            }
            
            serialized_data = self._serialize_data(prueba_data)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("pruebas_cached")
            self._increment_stat("pruebas_esf_cached")
            
            logger.info(f"ESF de prueba guardado: cliente={cliente_id}, periodo={periodo}, tipo={test_type}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando ESF de prueba: {e}")
            return False
    
    def get_prueba_esf(self, cliente_id: int, periodo: str, test_type: str = "current_system") -> Optional[Dict[str, Any]]:
        """
        Obtener ESF de prueba del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            test_type: Tipo de prueba
            
        Returns:
            Dict con ESF de prueba o None
        """
        key = self._get_key(cliente_id, periodo, f"pruebas:esf:{test_type}")
        
        try:
            data = self.redis_client.get(key)
            if data:
                esf_prueba = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("pruebas_retrieved")
                self._increment_stat("pruebas_esf_retrieved")
                
                logger.debug(f"ESF de prueba obtenido: cliente={cliente_id}, periodo={periodo}, tipo={test_type}")
                return esf_prueba
            else:
                self._increment_stat("cache_misses")
                logger.debug(f"ESF de prueba no encontrado: cliente={cliente_id}, periodo={periodo}, tipo={test_type}")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo ESF de prueba: {e}")
            self._increment_stat("cache_errors")
            return None
    
    def set_prueba_data(self, cliente_id: int, periodo: str, data_type: str, 
                       datos: Dict[str, Any], test_type: str = "general", ttl: int = None) -> bool:
        """
        Guardar datos de prueba gen√©ricos (no solo ESF)
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            data_type: Tipo de datos ("esf", "eri", "kpis", "movimientos", etc.)
            datos: Datos a guardar
            test_type: Tipo de prueba
            ttl: Tiempo de vida en segundos
            
        Returns:
            bool: True si se guard√≥ exitosamente
        """
        key = self._get_key(cliente_id, periodo, f"pruebas:{data_type}:{test_type}")
        ttl = ttl or self.default_ttl
        
        try:
            prueba_data = {
                **datos,
                '_metadata': {
                    'cliente_id': cliente_id,
                    'periodo': periodo,
                    'data_type': data_type,
                    'test_type': test_type,
                    'source': 'sistema_pruebas',
                    'created_at': datetime.now().isoformat(),
                    'ttl': ttl,
                    'tipo': 'prueba_data'
                }
            }
            
            serialized_data = self._serialize_data(prueba_data)
            self.redis_client.setex(key, ttl, serialized_data)
            
            self._increment_stat("cache_writes")
            self._increment_stat("pruebas_cached")
            self._increment_stat(f"pruebas_{data_type}_cached")
            
            logger.info(f"Datos de prueba guardados: cliente={cliente_id}, periodo={periodo}, tipo={data_type}, test={test_type}")
            return True
            
        except Exception as e:
            logger.error(f"Error guardando datos de prueba {data_type}: {e}")
            return False
    
    def get_prueba_data(self, cliente_id: int, periodo: str, data_type: str, 
                       test_type: str = "general") -> Optional[Dict[str, Any]]:
        """
        Obtener datos de prueba gen√©ricos del cache
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            data_type: Tipo de datos
            test_type: Tipo de prueba
            
        Returns:
            Dict con datos de prueba o None
        """
        key = self._get_key(cliente_id, periodo, f"pruebas:{data_type}:{test_type}")
        
        try:
            data = self.redis_client.get(key)
            if data:
                prueba_data = self._deserialize_data(data)
                self._increment_stat("cache_hits")
                self._increment_stat("pruebas_retrieved")
                self._increment_stat(f"pruebas_{data_type}_retrieved")
                
                logger.debug(f"Datos de prueba obtenidos: cliente={cliente_id}, periodo={periodo}, tipo={data_type}, test={test_type}")
                return prueba_data
            else:
                self._increment_stat("cache_misses")
                return None
                
        except Exception as e:
            logger.error(f"Error obteniendo datos de prueba {data_type}: {e}")
            self._increment_stat("cache_errors")
            return None
    
    def list_pruebas_cliente(self, cliente_id: int, periodo: str = None) -> List[Dict[str, str]]:
        """
        Listar todas las pruebas disponibles para un cliente
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo espec√≠fico (opcional)
            
        Returns:
            Lista de pruebas disponibles con metadata
        """
        try:
            if periodo:
                pattern = f"sgm:contabilidad:{cliente_id}:{periodo}:pruebas:*"
            else:
                pattern = f"sgm:contabilidad:{cliente_id}:*:pruebas:*"
            
            keys = self.redis_client.keys(pattern)
            pruebas = []
            
            for key in keys:
                parts = key.split(':')
                if len(parts) >= 6:  # sgm:contabilidad:cliente:periodo:pruebas:tipo:subtipo
                    prueba_info = {
                        'cliente_id': parts[2],
                        'periodo': parts[3],
                        'data_type': parts[5],
                        'test_type': parts[6] if len(parts) > 6 else 'general',
                        'redis_key': key
                    }
                    pruebas.append(prueba_info)
            
            logger.debug(f"Pruebas listadas para cliente {cliente_id}: {len(pruebas)} encontradas")
            return pruebas
            
        except Exception as e:
            logger.error(f"Error listando pruebas del cliente {cliente_id}: {e}")
            return []
    
    def invalidate_pruebas_cliente(self, cliente_id: int, periodo: str = None) -> int:
        """
        Invalidar todas las pruebas de un cliente (o per√≠odo espec√≠fico)
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo espec√≠fico (opcional)
            
        Returns:
            int: N√∫mero de claves eliminadas
        """
        try:
            if periodo:
                pattern = f"sgm:contabilidad:{cliente_id}:{periodo}:pruebas:*"
            else:
                pattern = f"sgm:contabilidad:{cliente_id}:*:pruebas:*"
            
            keys = self.redis_client.keys(pattern)
            
            if keys:
                deleted_count = self.redis_client.delete(*keys)
                self._increment_stat("cache_invalidations")
                self._increment_stat("pruebas_invalidated")
                
                logger.info(f"Pruebas invalidadas: cliente={cliente_id}, periodo={periodo or 'todos'}, claves_eliminadas={deleted_count}")
                return deleted_count
            return 0
            
        except Exception as e:
            logger.error(f"Error invalidando pruebas: {e}")
            return 0

    # ========== Utilidades y Gesti√≥n ==========
    def invalidate_cliente_periodo(self, cliente_id: int, periodo: str) -> int:
        """
        Invalidar todo el cache de un cliente/periodo espec√≠fico
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo contable
            
        Returns:
            int: N√∫mero de claves eliminadas
        """
        pattern = f"sgm:contabilidad:{cliente_id}:{periodo}:*"
        
        try:
            keys = self.redis_client.keys(pattern)
            
            if keys:
                deleted_count = self.redis_client.delete(*keys)
                self._increment_stat("cache_invalidations")
                
                logger.info(f"Cache invalidado: cliente={cliente_id}, periodo={periodo}, claves_eliminadas={deleted_count}")
                return deleted_count
            return 0
            
        except Exception as e:
            logger.error(f"Error invalidando cache: {e}")
            return 0
    
    def invalidate_cliente_all(self, cliente_id: int) -> int:
        """
        Invalidar todo el cache de un cliente (todos los per√≠odos)
        
        Args:
            cliente_id: ID del cliente
            
        Returns:
            int: N√∫mero de claves eliminadas
        """
        pattern = f"sgm:contabilidad:{cliente_id}:*"
        
        try:
            keys = self.redis_client.keys(pattern)
            
            if keys:
                deleted_count = self.redis_client.delete(*keys)
                self._increment_stat("cache_invalidations")
                
                logger.info(f"Cache completo invalidado: cliente={cliente_id}, claves_eliminadas={deleted_count}")
                return deleted_count
            return 0
            
        except Exception as e:
            logger.error(f"Error invalidando cache completo: {e}")
            return 0
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        Obtener estad√≠sticas completas del cache
        
        Returns:
            Dict con estad√≠sticas del cache
        """
        try:
            # Estad√≠sticas b√°sicas
            basic_stats = {
                'cache_hits': int(self.redis_client.get('sgm:stats:cache_hits') or 0),
                'cache_misses': int(self.redis_client.get('sgm:stats:cache_misses') or 0),
                'cache_writes': int(self.redis_client.get('sgm:stats:cache_writes') or 0),
                'cache_errors': int(self.redis_client.get('sgm:stats:cache_errors') or 0),
                'cache_invalidations': int(self.redis_client.get('sgm:stats:cache_invalidations') or 0),
            }
            
            # Estad√≠sticas espec√≠ficas por tipo
            specific_stats = {
                'kpis_cached': int(self.redis_client.get('sgm:stats:kpis_cached') or 0),
                'kpis_retrieved': int(self.redis_client.get('sgm:stats:kpis_retrieved') or 0),
                'esf_cached': int(self.redis_client.get('sgm:stats:esf_cached') or 0),
                'esf_retrieved': int(self.redis_client.get('sgm:stats:esf_retrieved') or 0),
                'movimientos_cached': int(self.redis_client.get('sgm:stats:movimientos_cached') or 0),
                'movimientos_retrieved': int(self.redis_client.get('sgm:stats:movimientos_retrieved') or 0),
                'procesamiento_updates': int(self.redis_client.get('sgm:stats:procesamiento_updates') or 0),
                'pruebas_cached': int(self.redis_client.get('sgm:stats:pruebas_cached') or 0),
                'pruebas_retrieved': int(self.redis_client.get('sgm:stats:pruebas_retrieved') or 0),
                'pruebas_esf_cached': int(self.redis_client.get('sgm:stats:pruebas_esf_cached') or 0),
                'pruebas_esf_retrieved': int(self.redis_client.get('sgm:stats:pruebas_esf_retrieved') or 0),
            }
            
            # Contadores de claves por tipo
            contabilidad_keys = self.redis_client.keys('sgm:contabilidad:*')
            key_counts = {
                'total_keys': len(contabilidad_keys),
                'kpis_keys': len([k for k in contabilidad_keys if ':kpis' in k]),
                'esf_keys': len([k for k in contabilidad_keys if ':esf' in k]),
                'movimientos_keys': len([k for k in contabilidad_keys if ':movimientos' in k]),
                'cuentas_keys': len([k for k in contabilidad_keys if ':cuentas' in k]),
                'procesamiento_keys': len([k for k in contabilidad_keys if ':procesamiento' in k]),
                'pruebas_keys': len([k for k in contabilidad_keys if ':pruebas:' in k]),
                'pruebas_esf_keys': len([k for k in contabilidad_keys if ':pruebas:esf:' in k]),
            }
            
            # C√°lculos derivados
            total_requests = basic_stats['cache_hits'] + basic_stats['cache_misses']
            hit_rate = round((basic_stats['cache_hits'] / total_requests * 100), 2) if total_requests > 0 else 0
            
            # Informaci√≥n del sistema Redis
            redis_info = self.redis_client.info('memory')
            memory_stats = {
                'used_memory_human': redis_info.get('used_memory_human', 'N/A'),
                'used_memory_peak_human': redis_info.get('used_memory_peak_human', 'N/A'),
                'connected_clients': self.redis_client.info('clients').get('connected_clients', 0),
            }
            
            return {
                **basic_stats,
                **specific_stats,
                **key_counts,
                **memory_stats,
                'hit_rate_percent': hit_rate,
                'last_updated': datetime.now().isoformat(),
                'db_index': 1,
                'cache_system_version': '1.0.0'
            }
            
        except Exception as e:
            logger.error(f"Error obteniendo estad√≠sticas: {e}")
            return {'error': str(e)}
    
    def get_client_periods(self, cliente_id: int) -> List[str]:
        """
        Obtener lista de per√≠odos en cache para un cliente
        
        Args:
            cliente_id: ID del cliente
            
        Returns:
            Lista de per√≠odos disponibles en cache
        """
        try:
            pattern = f"sgm:contabilidad:{cliente_id}:*"
            keys = self.redis_client.keys(pattern)
            
            # Extraer per√≠odos √∫nicos
            periods = set()
            for key in keys:
                parts = key.split(':')
                if len(parts) >= 4:
                    period = parts[3]  # sgm:contabilidad:{cliente_id}:{periodo}:{tipo}
                    periods.add(period)
            
            return sorted(list(periods))
            
        except Exception as e:
            logger.error(f"Error obteniendo per√≠odos del cliente {cliente_id}: {e}")
            return []
    
    def _increment_stat(self, stat_name: str) -> None:
        """
        Incrementar contador de estad√≠sticas de forma segura
        
        Args:
            stat_name: Nombre de la estad√≠stica a incrementar
        """
        try:
            self.redis_client.incr(f"sgm:stats:{stat_name}")
        except Exception as e:
            logger.debug(f"Error incrementando estad√≠stica {stat_name}: {e}")
    
    def check_connection(self) -> bool:
        """
        Verificar conexi√≥n a Redis
        
        Returns:
            bool: True si la conexi√≥n es exitosa
        """
        try:
            return self.redis_client.ping()
        except Exception as e:
            logger.error(f"Error verificando conexi√≥n Redis: {e}")
            return False
    
    def health_check(self) -> Dict[str, Any]:
        """
        Verificaci√≥n completa de salud del sistema de cache
        
        Returns:
            Dict con informaci√≥n de salud del sistema
        """
        try:
            start_time = datetime.now()
            
            # Test b√°sico de conexi√≥n
            ping_success = self.redis_client.ping()
            
            # Test de escritura/lectura
            test_key = "sgm:health_check:test"
            test_value = {"timestamp": start_time.isoformat(), "test": True}
            
            write_success = self.redis_client.setex(test_key, 60, json.dumps(test_value))
            read_data = self.redis_client.get(test_key)
            read_success = read_data is not None
            
            # Limpiar test
            self.redis_client.delete(test_key)
            
            response_time = (datetime.now() - start_time).total_seconds() * 1000
            
            return {
                'status': 'healthy' if (ping_success and write_success and read_success) else 'unhealthy',
                'ping': ping_success,
                'write': write_success,
                'read': read_success,
                'response_time_ms': round(response_time, 2),
                'db_index': 1,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    # ========== Retenci√≥n de Cierres con TTL ==========
    def set_estado_financiero_with_retention(self, cliente_id: int, periodo: str, 
                                           datos_esf: Dict[str, Any], datos_eri: Dict[str, Any],
                                           max_cierres_por_cliente: int = 2, 
                                           ttl_hours: int = 24*30) -> Dict[str, Any]:
        """
        Guardar ESF y ERI con retenci√≥n autom√°tica de solo los N cierres m√°s recientes por cliente.
        
        Funcionalidad:
        1. Guarda ESF y ERI para el per√≠odo especificado con TTL
        2. Mantiene solo los max_cierres_por_cliente m√°s recientes por cliente en Redis
        3. Elimina autom√°ticamente cierres antiguos cuando se excede el l√≠mite
        4. Los datos eliminados de Redis permanecen en la base de datos
        
        Args:
            cliente_id: ID del cliente
            periodo: Per√≠odo del cierre (formato YYYY-MM)
            datos_esf: Datos del Estado de Situaci√≥n Financiera
            datos_eri: Datos del Estado de Resultados Integral
            max_cierres_por_cliente: M√°ximo de cierres a mantener en Redis por cliente (default: 2)
            ttl_hours: Tiempo de vida en horas para cada cierre (default: 30 d√≠as)
            
        Returns:
            Dict con informaci√≥n del resultado de la operaci√≥n
        """
        try:
            ttl_seconds = ttl_hours * 3600
            resultado = {
                'success': True,
                'cliente_id': cliente_id,
                'periodo': periodo,
                'cierres_eliminados': [],
                'cierres_mantenidos': [],
                'error': None
            }
            
            logger.info(f"üîÑ Iniciando retenci√≥n de cierres para cliente {cliente_id}, per√≠odo {periodo}")
            
            # 1. Obtener todos los cierres existentes para este cliente
            pattern = f"sgm:contabilidad:{cliente_id}:*:esf"
            claves_existentes = self.redis_client.keys(pattern)
            
            # Extraer per√≠odos y fechas de creaci√≥n de las claves existentes
            cierres_existentes = []
            for clave in claves_existentes:
                try:
                    # Formato: sgm:contabilidad:{cliente_id}:{periodo}:esf
                    parts = clave.split(':')
                    if len(parts) >= 4:
                        periodo_existente = parts[3]
                        
                        # Obtener metadata para la fecha de creaci√≥n
                        datos_existentes = self.redis_client.get(clave)
                        if datos_existentes:
                            datos_parsed = json.loads(datos_existentes)
                            fecha_creacion = datos_parsed.get('_metadata', {}).get('created_at')
                            
                            if fecha_creacion:
                                cierres_existentes.append({
                                    'periodo': periodo_existente,
                                    'fecha_creacion': fecha_creacion,
                                    'clave_esf': clave,
                                    'clave_eri': clave.replace(':esf', ':eri')
                                })
                            else:
                                # Fallback: usar timestamp actual para claves sin metadata
                                cierres_existentes.append({
                                    'periodo': periodo_existente,
                                    'fecha_creacion': datetime.now().isoformat(),
                                    'clave_esf': clave,
                                    'clave_eri': clave.replace(':esf', ':eri')
                                })
                except Exception as e:
                    logger.warning(f"Error procesando clave existente {clave}: {e}")
                    continue
            
            # 2. Guardar el nuevo cierre (ESF y ERI)
            logger.info(f"üíæ Guardando nuevo cierre: cliente {cliente_id}, per√≠odo {periodo}")
            
            # Guardar ESF con TTL
            esf_guardado = self.set_estado_financiero(
                cliente_id=cliente_id,
                periodo=periodo,
                tipo_estado='esf',
                datos=datos_esf,
                ttl=ttl_seconds
            )
            
            # Guardar ERI con TTL
            eri_guardado = self.set_estado_financiero(
                cliente_id=cliente_id,
                periodo=periodo,
                tipo_estado='eri',
                datos=datos_eri,
                ttl=ttl_seconds
            )
            
            if not (esf_guardado and eri_guardado):
                resultado['success'] = False
                resultado['error'] = 'Error guardando ESF o ERI'
                return resultado
            
            # 3. Agregar el nuevo cierre a la lista
            nuevo_cierre = {
                'periodo': periodo,
                'fecha_creacion': datetime.now().isoformat(),
                'clave_esf': f"sgm:contabilidad:{cliente_id}:{periodo}:esf",
                'clave_eri': f"sgm:contabilidad:{cliente_id}:{periodo}:eri"
            }
            cierres_existentes.append(nuevo_cierre)
            
            # 4. Ordenar por fecha de creaci√≥n (m√°s reciente primero)
            cierres_existentes.sort(key=lambda x: x['fecha_creacion'], reverse=True)
            
            logger.info(f"üìä Total de cierres para cliente {cliente_id}: {len(cierres_existentes)}")
            logger.info(f"üìä L√≠mite m√°ximo configurado: {max_cierres_por_cliente}")
            
            # 5. Identificar cierres a mantener y eliminar
            cierres_a_mantener = cierres_existentes[:max_cierres_por_cliente]
            cierres_a_eliminar = cierres_existentes[max_cierres_por_cliente:]
            
            # 6. Eliminar cierres antiguos de Redis
            for cierre in cierres_a_eliminar:
                try:
                    claves_a_eliminar = [cierre['clave_esf'], cierre['clave_eri']]
                    
                    # Tambi√©n eliminar KPIs asociados si existen
                    clave_kpis = f"sgm:contabilidad:{cliente_id}:{cierre['periodo']}:kpis"
                    claves_a_eliminar.append(clave_kpis)
                    
                    eliminadas = self.redis_client.delete(*claves_a_eliminar)
                    
                    resultado['cierres_eliminados'].append({
                        'periodo': cierre['periodo'],
                        'fecha_creacion': cierre['fecha_creacion'],
                        'claves_eliminadas': eliminadas
                    })
                    
                    logger.info(f"üóëÔ∏è Cierre eliminado de Redis: cliente {cliente_id}, per√≠odo {cierre['periodo']}")
                    
                except Exception as e:
                    logger.error(f"Error eliminando cierre {cierre['periodo']}: {e}")
            
            # 7. Registrar cierres mantenidos
            for cierre in cierres_a_mantener:
                resultado['cierres_mantenidos'].append({
                    'periodo': cierre['periodo'],
                    'fecha_creacion': cierre['fecha_creacion']
                })
            
            # 8. Incrementar estad√≠sticas
            self._increment_stat("retention_operations")
            
            # Incrementar contadores individuales para cierres eliminados y mantenidos
            for _ in range(len(cierres_a_eliminar)):
                self._increment_stat("cierres_eliminados")
            for _ in range(len(cierres_a_mantener)):
                self._increment_stat("cierres_mantenidos")
            
            logger.info(f"‚úÖ Retenci√≥n completada para cliente {cliente_id}:")
            logger.info(f"   üìÅ Cierres mantenidos: {len(cierres_a_mantener)}")
            logger.info(f"   üóëÔ∏è Cierres eliminados: {len(cierres_a_eliminar)}")
            logger.info(f"   ‚è∞ TTL configurado: {ttl_hours} horas")
            
            return resultado
            
        except Exception as e:
            logger.error(f"Error en retenci√≥n de cierres para cliente {cliente_id}: {e}")
            return {
                'success': False,
                'cliente_id': cliente_id,
                'periodo': periodo,
                'error': str(e),
                'cierres_eliminados': [],
                'cierres_mantenidos': []
            }
    
    def get_cierres_disponibles_cliente(self, cliente_id: int) -> List[Dict[str, Any]]:
        """
        Obtener lista de cierres disponibles en Redis para un cliente espec√≠fico.
        
        Args:
            cliente_id: ID del cliente
            
        Returns:
            Lista de cierres disponibles con metadata
        """
        try:
            pattern = f"sgm:contabilidad:{cliente_id}:*:esf"
            claves_esf = self.redis_client.keys(pattern)
            
            cierres = []
            for clave in claves_esf:
                try:
                    # Extraer per√≠odo de la clave
                    parts = clave.split(':')
                    if len(parts) >= 4:
                        periodo = parts[3]
                        
                        # Verificar que tambi√©n existe ERI
                        clave_eri = clave.replace(':esf', ':eri')
                        existe_eri = self.redis_client.exists(clave_eri)
                        
                        if existe_eri:
                            # Obtener metadata
                            datos_esf = self.redis_client.get(clave)
                            if datos_esf:
                                datos_parsed = json.loads(datos_esf)
                                metadata = datos_parsed.get('_metadata', {})
                                
                                # Obtener TTL restante
                                ttl_restante = self.redis_client.ttl(clave)
                                
                                cierre_info = {
                                    'periodo': periodo,
                                    'fecha_creacion': metadata.get('created_at'),
                                    'ttl_restante_segundos': ttl_restante,
                                    'ttl_restante_horas': round(ttl_restante / 3600, 1) if ttl_restante > 0 else 0,
                                    'tiene_esf': True,
                                    'tiene_eri': True,
                                    'clave_esf': clave,
                                    'clave_eri': clave_eri
                                }
                                
                                cierres.append(cierre_info)
                
                except Exception as e:
                    logger.warning(f"Error procesando cierre {clave}: {e}")
                    continue
            
            # Ordenar por fecha de creaci√≥n (m√°s reciente primero)
            cierres.sort(key=lambda x: x.get('fecha_creacion', ''), reverse=True)
            
            logger.debug(f"Cierres disponibles para cliente {cliente_id}: {len(cierres)}")
            return cierres
            
        except Exception as e:
            logger.error(f"Error obteniendo cierres del cliente {cliente_id}: {e}")
            return []


# Instancia global del sistema de cache
# Se inicializa de forma lazy para evitar errores en import time
_cache_system = None

def get_cache_system() -> SGMCacheSystem:
    """
    Obtener instancia del sistema de cache (patr√≥n singleton)
    
    Returns:
        SGMCacheSystem: Instancia del sistema de cache
    """
    global _cache_system
    if _cache_system is None:
        _cache_system = SGMCacheSystem()
    return _cache_system
